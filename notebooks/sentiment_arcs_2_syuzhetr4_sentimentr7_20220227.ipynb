{"cells":[{"cell_type":"markdown","metadata":{"id":"AtxyCnlCcAi1"},"source":["# **Compute Sentiment Using 4 SyuzhetR and 7 SentimentR Models**\n","\n","* https://www.youtube.com/watch?v=U3ByGh8RmSc\n","\n","* https://github.com/ttimbers/intro-to-reticulate\n","\n","[Use R on Google Colab!](https://colab.research.google.com/notebook#create=true&language=r)"]},{"cell_type":"markdown","source":["# **[STEP 1] Configuration and Setup**"],"metadata":{"id":"mB542sPZq6YT"}},{"cell_type":"markdown","metadata":{"id":"mGoFJmeFkTxk"},"source":["## Configure Jupyter Notebook"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"0CkX9gONAsmp"},"outputs":[],"source":["# Ignore warnings\n","\n","import warnings\n","warnings.filterwarnings('ignore')"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"kK8zKENjsyig"},"outputs":[],"source":["# Configure Jupyter\n","\n","# Enable multiple outputs from one code cell\n","from IPython.core.interactiveshell import InteractiveShell\n","InteractiveShell.ast_node_interactivity = \"all\"\n","\n","from IPython.display import display\n","from IPython.display import Image\n","from ipywidgets import widgets, interactive"]},{"cell_type":"markdown","source":["## [INPUT] Connect Google gDrive to this Jupyter Notebook"],"metadata":{"id":"qkcsI681TaDM"}},{"cell_type":"code","execution_count":null,"metadata":{"id":"2bfkqjgMiw7T"},"outputs":[],"source":["# [INPUT REQUIRED]: Authorize access to Google gDrive\n","\n","# Connect this Notebook to your permanent Google Drive\n","#   so all generated output is saved to permanent storage there\n","\n","try:\n","  from google.colab import drive\n","  IN_COLAB=True\n","except:\n","  IN_COLAB=False\n","\n","if IN_COLAB:\n","  print(\"Attempting to attach your Google gDrive to this Colab Jupyter Notebook\")\n","  drive.mount('/gdrive')\n","else:\n","  print(\"Your Google gDrive is attached to this Colab Jupyter Notebook\")"]},{"cell_type":"code","source":["!ls"],"metadata":{"id":"2gZ5EozgsITG"},"execution_count":null,"outputs":[]},{"cell_type":"code","execution_count":null,"metadata":{"id":"lpxXvi4Xi9VP"},"outputs":[],"source":["# [CUSTOMIZE]: Change the text after the Unix '%cd ' command below (change directory)\n","#              to math the full path to your gDrive subdirectory which should be the \n","#              root directory cloned from the SentimentArcs github repo.\n","\n","# NOTE: Make sure this subdirectory already exists and there are \n","#       no typos, spaces or illegals characters (e.g. periods) in the full path after %cd\n","\n","# NOTE: In Python all strings must begin with an upper or lowercase letter, and only\n","#         letter, number and underscores ('_') characters should appear afterwards.\n","#         Make sure your full path after %cd obeys this constraint or errors may appear.\n","\n","\n","\n","# Step #1: Get full path to SentimentArcs subdir on gDrive\n","# =======\n","#@markdown **Accept default path on gDrive or Enter new one:**\n","\n","Path_to_SentimentArcs = \"/gdrive/MyDrive/cdh/sentiment_arcs/\" #@param [\"/gdrive/MyDrive/sentiment_arcs/\"] {allow-input: true}\n","\n","#@markdown (e.g. /gdrive/MyDrive/research/sentiment_arcs/)\n","\n","\n","\n","# Step #2: Move to Parent directory of Sentiment_Arcs\n","# =======\n","parentdir_sentiment_arcs = '/'.join(Path_to_SentimentArcs.split('/')[:-2])\n","print(f'subdir_parent: {parentdir_sentiment_arcs}')\n","%cd $parentdir_sentiment_arcs\n","\n","\n","# Step #3: If project sentiment_arcs subdir does not exist, \n","#          clone it from github\n","# =======\n","import os\n","\n","if not os.path.isdir('sentiment_arcs'):\n","  # NOTE: This will not work until SentimentArcs becomes an open sourced PUBLIC repo\n","  # !git clone https://github.com/jon-chun/sentiment_arcs.git\n","\n","  # Test on open access github repo\n","  !git clone https://github.com/jon-chun/nabokov_palefire.git\n","\n","\n","# Step #4: Change into sentiment_arcs subdir\n","# =======\n","%cd ./sentiment_arcs\n","# Test on open acess github repo\n","# %cd ./nabokov_palefire\n","\n","# Step #5: Confirm contents of sentiment_arcs subdir\n","# =======\n","!ls\n"]},{"cell_type":"code","source":["# [VERIFY]: Ensure that all the manually preprocessed novel are in plain text\n","#   files and file names are formatted correctly\n","\n","# %cd ../sentiment_arcs\n","!pwd\n","!ls ./text_raw"],"metadata":{"id":"OC45d6qejNOs"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["## Define Directory Tree Structure"],"metadata":{"id":"XVWagkv16GKQ"}},{"cell_type":"code","source":["#@markdown **Sentiment Arcs Directory Structure** \\\n","#@markdown \\\n","#@markdown **1. Input Directories:** \\\n","#@markdown (a) Raw textfiles in subdir: ./text_raw/(text_type)/  \\\n","#@markdown (b) Cleaned textfiles in subdir: ./text_clean/(text_type)/ \\\n","#@markdown \\\n","#@markdown **2. Output Directories** \\\n","#@markdown (1) Raw Sentiment time series datafiles and plots in subdir: ./sentiment_raw/(text_type) \\\n","#@markdown (2) Cleaned Sentiment time series datafiles and plots in subdir: ./sentiment_clean/(text_type) \\\n","#@markdown \\\n","#@markdown **Which type of texts are you analyzing?** \\\n","\n","Text_Type = \"novels\" #@param [\"novels\", \"social_media\", \"finance\"]\n","\n","#@markdown Please check that the required textfiles and datafiles exist in the correct subdirectories before continuing.\n","\n","\n"],"metadata":{"id":"nGW9SSRQ6SoU"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Create Directory CONSTANTS based On Document Type\n","\n","SUBDIR_TEXT_RAW = f\"./text_raw/{Text_Type}_raw/\"\n","SUBDIR_TEXT_CLEAN = f\"./text_clean/{Text_Type}_clean/\"\n","SUBDIR_SENTIMENT_RAW = f\"./sentiment_raw/{Text_Type}_raw/\"\n","SUBDIR_SENTIMENT_CLEAN = f\"./sentiment_clean/{Text_Type}_clean/\"\n","SUBDIR_PLOTS = f\"./plots/{Text_Type}_plots/\"\n","\n","# Verify Directory Structure\n","\n","print('Verify the Directory Structure:\\n')\n","print('-------------------------------\\n')\n","\n","print(f'           [Corpus Type]: {Text_Type}\\n')\n","print(f'       [SUBDIR_TEXT_RAW]: {SUBDIR_TEXT_RAW}\\n')\n","print(f'     [SUBDIR_TEXT_CLEAN]: {SUBDIR_TEXT_CLEAN}\\n')\n","print(f'  [SUBDIR_SENTIMENT_RAW]: {SUBDIR_SENTIMENT_RAW}\\n')\n","print(f'[SUBDIR_SENTIMENT_CLEAN]: {SUBDIR_SENTIMENT_CLEAN}\\n')\n","print(f'          [SUBDIR_PLOTS]: {SUBDIR_PLOTS}\\n')"],"metadata":{"id":"xS2aWqAc6FEu"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["## Read YAML Configuration File"],"metadata":{"id":"lb6GazCLrg0o"}},{"cell_type":"code","source":["!pip install pyyaml"],"metadata":{"id":"lnf1TH0wrcg2"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["import yaml"],"metadata":{"id":"o8nzqnBVrcg3"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"Ns5NwArZmush"},"source":["### Define Texts to Analyze"]},{"cell_type":"code","source":["# Read SentimentArcs YAML Config Files for Different Corpora Types(3) and Text Files Details\n","\n","# Novel Text Files\n","with open(\"./config/novels_info.yaml\", \"r\") as stream:\n","  try:\n","    novels_dt = yaml.safe_load(stream)\n","  except yaml.YAMLError as exc:\n","    print(exc)\n","\n","# Finance Text Files\n","with open(\"./config/finance_info.yaml\", \"r\") as stream:\n","  try:\n","    finance_dt = yaml.safe_load(stream)\n","  except yaml.YAMLError as exc:\n","    print(exc)\n","\n","# Social Media Text Files\n","\n","with open(\"./config/social_info.yaml\", \"r\") as stream:\n","  try:\n","    social_dt = yaml.safe_load(stream)\n","  except yaml.YAMLError as exc:\n","    print(exc)"],"metadata":{"id":"hm_secNnpKjl"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["import json"],"metadata":{"id":"10r5k1kku8nI"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Verify the Corpora: Novel Textfiles in novels_dt\n","\n","print (json.dumps(novels_dt, indent=2))"],"metadata":{"id":"QUh7oSH9unu3"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Verify the Corpora: Novel Textfiles in finance_dt\n","\n","print (json.dumps(finance_dt, indent=2))"],"metadata":{"id":"I3Bdv_hUvDvV"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Verify the Corpora: Novel Textfiles in social_dt\n","\n","print (json.dumps(social_dt, indent=2))"],"metadata":{"id":"JQ6gqk3fvDpQ"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"aG4DtHQ1sgj0"},"source":["## Define Globals"]},{"cell_type":"code","source":["# TODO"],"metadata":{"id":"5_cAI7NFviIU"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"uNwIAUc6uDdo"},"source":["## Install Libraries: R"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"p05_XBc6uBrK"},"outputs":[],"source":["# !pip install rpy2"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"83BAG8HPS0-f"},"outputs":[],"source":["# !pip install -U rpy2"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"x4zeGVURuJ9r"},"outputs":[],"source":["# Load Jupyter rpy2 Extension  \n","#   enables the %%R magic commands\n","\n","%load_ext rpy2.ipython"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"Epid7gshS8k3"},"outputs":[],"source":["# %reload_ext rpy2.ipython"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"DgF1pBDQuVKY"},"outputs":[],"source":["%%time \n","%%capture \n","%%R\n","\n","# Install Syuzhet.R, Sentiment.R and Utility Libraries\n","\n","# NOTE: 1m12s \n","#       1m05s\n","\n","install.packages(c('syuzhet', 'sentimentr', 'tidyverse', 'lexicon'))\n","\n","library(syuzhet)\n","library(sentimentr)\n","library(tidyverse)\n","library(lexicon)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"wTDXivt_TPQD"},"outputs":[],"source":["# %reload_ext rpy2.ipython"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"XUmxULxnKqQb"},"outputs":[],"source":["# Load Python libraries to exchange data with R Program Space and read R Datafiles\n","\n","import rpy2.robjects as robjects\n","from rpy2.robjects.packages import importr"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"StqQYI0Aq8mE"},"outputs":[],"source":["%%R\n","\n","# Verify R in Kernel Version\n","\n","R.version.string"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"fQTZyrZzH-XZ"},"outputs":[],"source":["%%R\n","\n","# Verify R Kernel Session Info\n","\n","sessionInfo()"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"dioCyXqZABym"},"outputs":[],"source":["%%R\n","\n","# Verfiy R Kernel Environment\n","\n","# Sys.getenv\n"]},{"cell_type":"markdown","metadata":{"id":"If55aLQYsk_K"},"source":["## Install Libraries: Python"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"oVNT7dGQsmw3"},"outputs":[],"source":["import numpy as np\n","import pandas as pd\n","import matplotlib.pyplot as plt\n","import seaborn as sns\n","\n","%matplotlib inline"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"emaLq2QGn0rw"},"outputs":[],"source":["from glob import glob\n","import copy\n","import json"]},{"cell_type":"markdown","metadata":{"id":"EA1yTaY_9Qod"},"source":["## Setup Matplotlib Style\n","\n","* https://matplotlib.org/stable/tutorials/introductory/customizing.html"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"Y1s24O-S9JJX"},"outputs":[],"source":["from cycler import cycler\n","\n","colors = ['#1f77b4', '#ff7f0e', '#2ca02c', '#d62728', '#9467bd', '#8c564b', '#e377c2', '#7f7f7f', '#bcbd22', '#17becf']   \n","linestyles = ['-', '--', ':', '-.','-', '--', ':', '-.','-', '--']\n","\n","cycle = plt.cycler(\"color\", colors) + plt.cycler(\"linestyle\", linestyles)\n","\n","# View previous matplotlib configuration\n","print('\\n Old Matplotlib Configurtion Settings:\\n')\n","# plt.rc.show\n","print('\\n\\n')\n","\n","# Update and view new matplotlib configuration\n","print('\\n New Matplotlib Configurtion Settings:\\n')\n","myparams = {'axes.prop_cycle': cycle}\n","plt.rcParams.update(myparams)\n","\n","plt.rcParams[\"axes.titlesize\"] = 16\n","plt.rcParams['figure.figsize'] = 20,10\n","plt.rcParams[\"legend.fontsize\"] = 10\n","plt.rcParams[\"xtick.labelsize\"] = 12\n","plt.rcParams[\"ytick.labelsize\"] = 12\n","plt.rcParams[\"axes.labelsize\"] = 12\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"O9noShbNaHV1"},"outputs":[],"source":["\"\"\"\n","import matplotlib.colors as mcolors\n","\n","mcolors.TABLEAU_COLORS\n","\n","all_named_colors = {}\n","all_named_colors.update(mcolors.TABLEAU_COLORS)\n","\n","print('\\n')\n","all_named_colors.values()\n","\"\"\";"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"M5A41pzM9aJY"},"outputs":[],"source":["# Set matplotlib plot figure.figsize\n","\n","new_plt_size = plt.rcParams[\"figure.figsize\"]=(20,10)\n","\n","print(\" New figure size: \",new_plt_size)"]},{"cell_type":"markdown","metadata":{"id":"7dPPrZwyIIze"},"source":["## Setup Seaborn Style"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"hM3oRY-UOmzX"},"outputs":[],"source":["# View previous seaborn configuration\n","print('\\n Old Seaborn Configurtion Settings:\\n')\n","sns.axes_style()\n","print('\\n\\n')\n","\n","# Update and View new seaborn configuration\n","print('\\n New Seaborn Configurtion Settings:\\n')\n","# sns.set_style('white')\n","sns.set_context('paper')\n","sns.set_style('white')\n","sns.set_palette('tab10')\n","\n","# Change defaults\n","# sns.set(style='white', context='talk', palette='tab10')"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"22vaCL09Iaja"},"outputs":[],"source":["# Seaborn: Set Theme (Scale of Font)\n","\n","sns.set_theme('paper')  # paper, notebook, talk, poster\n","\n","\n","# Seaborn: Set Context\n","# sns.set_context(\"notebook\")\n","\n","\n","\n","# Seaborn: Set Style\n","\n","# sns.set_style('ticks') # darkgrid, whitegrid, dark, white, and ticks"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"a2upm4ohIWcI"},"outputs":[],"source":["# Seaborn: Default Palette (Pastel?)\n","\n","sns.color_palette()"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"XpIbYX-DIWcJ"},"outputs":[],"source":["# Seaborn: Set to High-Contrast Palette (more Vision Impaired Friendly)\n","\n","sns.set_palette('tab10')\n","sns.color_palette()"]},{"cell_type":"code","source":["plt.style.available"],"metadata":{"id":"R1U4pM1ri4Te"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["plt.style.use('seaborn-whitegrid')"],"metadata":{"id":"gWOxcTgbi6Wx"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"X229IbToHwa2"},"source":["## Python Utility Functions"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"HqZri_3GHvqc"},"outputs":[],"source":["# Utility functions to read/write nested Dictionary (key=novel) of DataFrames (Cols = Model Sentiment Series) \n","\n","def write_dict_dfs(adict, out_file='sentiments.json', out_dir=SUBDIR_SENTIMENT_RAW):\n","  '''\n","  Given a Dictionary of DataFrames and optional output filename and output directory\n","  Write as nested json file\n","  '''\n","\n","  # convert dataframes into dictionaries\n","  data_dict = {\n","      key: adict[key].to_dict(orient='records') \n","      for key in adict.keys()\n","  }\n","\n","  # write to disk\n","  out_fullpath = f'{out_dir}{out_file}'\n","  print(f'Saving file to: {out_fullpath}')\n","  with open(out_fullpath, 'w') as fp:\n","    json.dump(\n","      data_dict, \n","      fp, \n","      indent=4, \n","      sort_keys=True\n","    )\n","\n","  return \n","\n","def read_dict_dfs(in_file='sentiments.json', in_dir=SUBDIR_SENTIMENT_RAW):\n","  '''\n","  Given a Dictionary of DataFrames and optional output filename and output directory\n","  Read nested json file into Dictionary of DataFrames\n","  '''\n","\n","  # read from disk\n","  in_fullpath = f'{in_dir}{in_file}'\n","  with open(in_fullpath, 'r') as fp:\n","      data_dict = json.load(fp)\n","\n","  # convert dictionaries into dataframes\n","  all_dt = {\n","      key: pd.DataFrame(data_dict[key]) \n","      for key in data_dict\n","  }\n","\n","  return all_dt"]},{"cell_type":"markdown","metadata":{"id":"fys3dkJSB656"},"source":["# **[STEP 2] Read all Preprocessed Novels**"]},{"cell_type":"code","source":["!pwd"],"metadata":{"id":"Roq-2Ol8yH5c"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["SUBDIR_TEXT_CLEAN"],"metadata":{"id":"JA-jWmcfyHya"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["!ls $SUBDIR_TEXT_CLEAN"],"metadata":{"id":"mnw6XRAIyN_s"},"execution_count":null,"outputs":[]},{"cell_type":"code","execution_count":null,"metadata":{"id":"2ClL4-1Gqe7g"},"outputs":[],"source":["# Create a List (preprocessed_ls) of all preprocessed text files\n","\n","try:\n","    preprocessed_ls = glob(f'{SUBDIR_TEXT_CLEAN}*.csv')\n","    preprocessed_ls = [x.split('/')[-1] for x in preprocessed_ls]\n","    preprocessed_ls = [x.split('.')[0] for x in preprocessed_ls]\n","except IndexError:\n","    raise RuntimeError('No csv file found')\n","\n","print('\\n'.join(preprocessed_ls))\n","print('\\n')\n","print(f'Found {len(preprocessed_ls)} Preprocessed files in {SUBDIR_TEXT_CLEAN}')"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"S4CqJQY9rNRw"},"outputs":[],"source":["# Read all preprocessed text files into master DataFrame (corpus_dt)\n","\n","corpus_dt = {}\n","\n","for i,anovel in enumerate(preprocessed_ls):\n","  print(f'Processing #{i}: {anovel}...')\n","  afile_fullpath = f'{SUBDIR_TEXT_CLEAN}{anovel}.csv'\n","  print(f'               {afile_fullpath}')\n","  anovel_df = pd.read_csv(afile_fullpath)\n","  corpus_dt[anovel] = anovel_df"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"QHLt5o78tJyR"},"outputs":[],"source":["# Verify the novels read into master Dictionary of DataFrames\n","\n","corpus_dt.keys()\n","print('\\n')\n","print(f'There were {len(corpus_dt)} preprocessed novels read into the Dict corpus_dt')"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"0JI2z5wCz8zz"},"outputs":[],"source":["# Check if there are any Null strings in the text_clean columns\n","\n","for i, anovel in enumerate(list(corpus_dt.keys())):\n","  print(f'\\nNovel #{i}: {anovel}')\n","  nan_ct = corpus_dt[anovel].text_clean.isna().sum()\n","  if nan_ct > 0:\n","    print(f'      {nan_ct} Null strings in the text_clean column')"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"mgLyDNrYzTuF"},"outputs":[],"source":["# Fill in all the Null value of text_clean with placeholder 'empty_string'\n","\n","for i, anovel in enumerate(list(corpus_dt.keys())):\n","  # print(f'Novel #{i}: {anovel}')\n","  # Fill all text_clean == Null with 'empty_string' so sentimentr::sentiment doesn't break\n","  corpus_dt[anovel][corpus_dt[anovel].text_clean.isna()] = 'empty_string'"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"O7gE08b_rNPH"},"outputs":[],"source":["# Verify one DataFrame in the master Dictionary\n","\n","corpus_dt['dbrown_thedavincicode'].head()"]},{"cell_type":"markdown","metadata":{"id":"GuoJERbI0wEJ"},"source":["# **[STEP 3] Get Sentiments with SyuzhetR (4 Models)**"]},{"cell_type":"markdown","metadata":{"id":"99hi2_XPomrT"},"source":["## Option (a): Read Previously Computed SyuzhetR Values from Datafiles"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"8fNpTykSorBy"},"outputs":[],"source":["# Read in Saved SyuzhetR Datafile from subdir_sentiments/all_4syuzhetr.json\n","\n","corpus_syuzhetr_dt = read_dict_dfs('all_4syuzhetr.json')\n","corpus_syuzhetr_dt.keys()"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"AV2P9VeQpiY2"},"outputs":[],"source":["# Verify all the Novels have 4 Syuzhet Model Values\n","\n","for i, anovel in enumerate(list(corpus_syuzhetr_dt.keys())):\n","  print(f'Novel #{i}: {anovel}')\n","  corpus_syuzhetr_dt[anovel].drop(columns=['Unnamed: 0'], inplace=True)\n","  print(f'      df.shape: {corpus_syuzhetr_dt[anovel].shape}')"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"IC7BnYPwpBQ5"},"outputs":[],"source":["# Verify DataFrame for test novel\n","\n","novel_str = 'cdickens_achristmascarol'\n","corpus_syuzhetr_dt[novel_str].head()"]},{"cell_type":"markdown","metadata":{"id":"ZMS53E-CorWs"},"source":["## Option (b): Compute New SyuzhetR Values"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"h94o_8qOAINH"},"outputs":[],"source":["# Verify text_clean of sample text\n","\n","text_sample = 'cdickens_achristmascarol'\n","\n","corpus_dt[text_sample]['text_clean'].to_list()[:10]"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"qDAb6bHqya1-"},"outputs":[],"source":["%%time\n","\n","# Compute Sentiments from all 4 Syuzhet Models applied to all 32 Novels (4 x 32 = 128 runs)\n","\n","# NOTE:  9m45s 23:30 on 20220114 Colab Pro (33 Novels)\n","#       28:32s 21:06 on 20220226 Colab Pro (33 Novels)\n","\n","# base = importr('base')\n","syuzhet = importr('syuzhet')\n","\n","# corpus_syuzhetr_dt = {}\n","\n","# base.rank(0, na_last = True)\n","novels_keys_ls = list(corpus_dt.keys())\n","novels_keys_ls.sort()\n","for i, anovel in enumerate(novels_keys_ls):\n","  print(f'Processing Novel #{i}: {anovel}...')\n","  corpus_dt[anovel]['syuzhetr_syuzhet'] = syuzhet.get_sentiment(corpus_dt[anovel]['text_clean'].to_list(), method='syuzhet')\n","  corpus_dt[anovel]['syuzhetr_bing'] = syuzhet.get_sentiment(corpus_dt[anovel]['text_clean'].to_list(), method='bing')\n","  corpus_dt[anovel]['syuzhetr_afinn'] = syuzhet.get_sentiment(corpus_dt[anovel]['text_clean'].to_list(), method='afinn')\n","  corpus_dt[anovel]['syuzhetr_nrc'] = syuzhet.get_sentiment(corpus_dt[anovel]['text_clean'].to_list(), method='nrc')"]},{"cell_type":"markdown","metadata":{"id":"SR9X7JGEqkMV"},"source":["## Checkpoint: Save SyuzhetR Values"]},{"cell_type":"code","source":["# Verify in SentimentArcs Root Directory\n","\n","!pwd\n","print('\\n')\n","!ls"],"metadata":{"id":"Durdojkm7zl5"},"execution_count":null,"outputs":[]},{"cell_type":"code","execution_count":null,"metadata":{"id":"xFJ0Sj45_Hba"},"outputs":[],"source":["# Verify Save Destination Subdir: SUBDIR_SENTIMENT_RAW\n","\n","SUBDIR_SENTIMENT_RAW\n","print('\\n')\n","!ls $SUBDIR_SENTIMENT_RAW"]},{"cell_type":"code","source":["corpus_dt.keys()"],"metadata":{"id":"EbiBAtrg9lJe"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["corpus_dt['cdickens_achristmascarol']"],"metadata":{"id":"ElS6K_8R9nkX"},"execution_count":null,"outputs":[]},{"cell_type":"code","execution_count":null,"metadata":{"id":"0-Kzyc3FEZ71"},"outputs":[],"source":["# Save sentiment values to subdir_sentiments\n","\n","write_dict_dfs(corpus_dt, out_file='all_4syuzhetr.json', out_dir=SUBDIR_SENTIMENT_RAW)"]},{"cell_type":"code","source":["# Verify Dictionary was saved correctly by reading back the *.json datafile\n","\n","test_dt = read_dict_dfs(in_file='all_4syuzhetr.json', in_dir=SUBDIR_SENTIMENT_RAW)\n","test_dt.keys()"],"metadata":{"id":"WTjSK5KX-BQm"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"nbQbIO9iqHUo"},"source":["## Plot SyuzhetR 4 Models"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"wxfVwdKvudRa"},"outputs":[],"source":["#@markdown Select option to save plots:\n","Save_Raw_Plots = True #@param {type:\"boolean\"}\n","\n","Save_Smooth_Plots = True #@param {type:\"boolean\"}\n","Resolution = \"300\" #@param [\"100\", \"300\"]\n","\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"Y5TXvTTAsPur"},"outputs":[],"source":["# Get Col Names for all 4 SyuzhetR Models\n","\n","cols_all_ls = corpus_dt['cdickens_achristmascarol'].columns\n","cols_syuzhetr_ls = [x for x in cols_all_ls if 'syuzhetr_' in x]\n","cols_syuzhetr_ls"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"bzMQ3Sl8trUw"},"outputs":[],"source":["novels_dt['cdickens_achristmascarol'][0]"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"ET8xiEY6vrCT"},"outputs":[],"source":["SUBDIR_PLOTS"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"5lkWMeKU2BnK"},"outputs":[],"source":["# Verify 4 SyuzhetR Models with Plots\n","\n","for i, anovel in enumerate(list(corpus_dt.keys())):\n","\n","  print(f'Novel #{i}: {novels_dt[anovel][0]}')\n","\n","  # Raw Sentiments \n","  fig = corpus_dt[anovel][cols_syuzhetr_ls].plot(title=f'{novels_dt[anovel][0]}\\n SyuzhetR 4 Models: Raw Sentiments', alpha=0.3)\n","  plt.show();\n","\n","  if Save_Raw_Plots:\n","    plt.savefig(f'{SUBDIR_PLOTS}plot_syuzhetr_raw_{anovel}_dpi{Resolution}.png', dpi=int(Resolution))\n","\n","  \n","  # Smoothed Sentiments (SMA 10%)\n","  # novel_sample = 'cdickens_achristmascarol'\n","  win_10per = int(corpus_dt[anovel].shape[0] * 0.1)\n","  corpus_dt[anovel][cols_syuzhetr_ls].rolling(win_10per, center=True, min_periods=0).mean().plot(title=f'{novels_dt[anovel][0]}\\n SyuzhetR 4 Models: Smoothed Sentiments (SMA 10%)', alpha=0.3)\n","  plt.show();\n","\n","  if Save_Smooth_Plots:\n","    plt.savefig(f'{SUBDIR_PLOTS}plot_syuzhetr_smooth10sma_{anovel}_dpi{Resolution}.png', dpi=int(Resolution))\n"]},{"cell_type":"markdown","metadata":{"id":"yl8og94l09WX"},"source":["# **[STEP 4] Get Sentiments with SentimentR (7 Models)**"]},{"cell_type":"markdown","metadata":{"id":"_N9zLYYpxq0f"},"source":["## Option (a): Read Previous Computed SentimentR Values from DataFile"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"nacTYi6ax4k5"},"outputs":[],"source":["# Read in Saved SyuzhetR Datafile from subdir_sentiments/all_4syuzhetr.json\n","\n","corpus_sentimentr_dt = read_dict_dfs('all_7sentimentr.json')\n","corpus_sentimentr_dt.keys()"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"AXsPH_3Vx4k8"},"outputs":[],"source":["# Verify all the Novels have 4 Syuzhet Model Values\n","\n","for i, anovel in enumerate(list(corpus_sentimentr_dt.keys())):\n","  print(f'Novel #{i}: {anovel}')\n","  corpus_sentimentr_dt[anovel].drop(columns=['Unnamed: 0'], inplace=True)\n","  print(f'      df.shape: {corpus_sentimentr_dt[anovel].shape}')"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"QjPDtuaMx4k9"},"outputs":[],"source":["# Verify DataFrame for test novel\n","\n","novel_str = 'cdickens_achristmascarol'\n","corpus_sentimentr_dt[novel_str].head()"]},{"cell_type":"markdown","metadata":{"id":"AQeJ5VtmkX3I"},"source":["## Option (b): Compute New SentimentR Values\n","\n","Call function in external get_sentimentr.R from within Python Loop\n","\n","* https://medium.com/analytics-vidhya/calling-r-from-python-magic-of-rpy2-d8cbbf991571\n","\n","* https://rpy2.github.io/doc/v3.0.x/html/generated_rst/pandas.html"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"DjytKCXPjZ_o"},"outputs":[],"source":["%%file get_sentimentr.R\n","\n","library(sentimentr)\n","library(lexicon)\n","\n","get_sentimentr_values <- function(s_v) {\n","  \n","  print('Processing sentimentr_jockersrinker')\n","  sentimentr_jockersrinker <- sentiment(s_v, polarity_dt=lexicon::hash_sentiment_jockers_rinker, \n","                                        hypen=\"\", amplifier.weight=0.8, n.before=5, n.after=2,\n","                                        adversative.weight=0.25, neutral.nonverb.like = FALSE, missing_value = 0)\n","\n","  print('Processing sentimentr_jockers')\n","  sentimentr_jockers <- sentiment(s_v, polarity_dt=lexicon::hash_sentiment_jockers, \n","                                        hypen=\"\", amplifier.weight=0.8, n.before=5, n.after=2,\n","                                        adversative.weight=0.25, neutral.nonverb.like = FALSE, missing_value = 0)\n","\n","  print('Processing sentimentr_huliu')\n","  sentimentr_huliu <- sentiment(s_v, polarity_dt=lexicon::hash_sentiment_huliu, \n","                                        hypen=\"\", amplifier.weight=0.8, n.before=5, n.after=2,\n","                                        adversative.weight=0.25, neutral.nonverb.like = FALSE, missing_value = 0)\n","\n","  print('Processing sentimentr_nrc')\n","  sentimentr_nrc <- sentiment(s_v, polarity_dt=lexicon::hash_sentiment_nrc, \n","                                        hypen=\"\", amplifier.weight=0.8, n.before=5, n.after=2,\n","                                        adversative.weight=0.25, neutral.nonverb.like = FALSE, missing_value = 0)\n","\n","  print('Processing sentimentr_senticnet')\n","  sentimentr_senticnet <- sentiment(s_v, polarity_dt=lexicon::hash_sentiment_senticnet, \n","                                        hypen=\"\", amplifier.weight=0.8, n.before=5, n.after=2,\n","                                        adversative.weight=0.25, neutral.nonverb.like = FALSE, missing_value = 0)\n","\n","  print('Processing sentimentr_sentiword')\n","  sentimentr_sentiword <- sentiment(s_v, polarity_dt=lexicon::hash_sentiment_sentiword, \n","                                        hypen=\"\", amplifier.weight=0.8, n.before=5, n.after=2,\n","                                        adversative.weight=0.25, neutral.nonverb.like = FALSE, missing_value = 0)\n","\n","  print('Processing sentimentr_loughran_mcdonald')\n","  sentimentr_loughran_mcdonald <- sentiment(s_v, polarity_dt=lexicon::hash_sentiment_loughran_mcdonald, \n","                                        hypen=\"\", amplifier.weight=0.8, n.before=5, n.after=2,\n","                                        adversative.weight=0.25, neutral.nonverb.like = FALSE, missing_value = 0)\n","\n","  print('Processing sentimentr_socal_google')\n","  sentimentr_socal_google <- sentiment(s_v, polarity_dt=lexicon::hash_sentiment_socal_google, \n","                                        hypen=\"\", amplifier.weight=0.8, n.before=5, n.after=2,\n","                                        adversative.weight=0.25, neutral.nonverb.like = FALSE, missing_value = 0)\n","\n","  anovel_sentimentr_df <- data.frame('text_clean' = s_v,\n","                                'sentimentr_jockersrinker' = sentimentr_jockersrinker$sentiment,\n","                                'sentimentr_jockers' = sentimentr_jockers$sentiment,\n","                                'sentimentr_huliu' = sentimentr_huliu$sentiment,\n","                                'sentimentr_nrc' = sentimentr_nrc$sentiment,\n","                                'sentimentr_senticnet' = sentimentr_senticnet$sentiment,\n","                                'sentimentr_sentiword' = sentimentr_sentiword$sentiment,\n","                                'sentimentr_loughran_mcdonald' = sentimentr_loughran_mcdonald$sentiment,\n","                                'sentimentr_socal_google' = sentimentr_socal_google$sentiment\n","                                )\n","  return(anovel_sentimentr_df)\n","\n","}"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"baykTTfbkROx"},"outputs":[],"source":["# Verify the *.R file above was written correctly\n","\n","!cat get_sentimentr.R"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"zGpOb1CNkRLJ"},"outputs":[],"source":["# Setup python robject with external library::function()\n","# https://rpy2.github.io/doc/v3.0.x/html/generated_rst/pandas.html\n","\n","# import rpy2.robjects as robjects\n","\n","# Defining the R script and loading the instance in Python\n","# from rpy2.robjects import pandas2ri \n","r = robjects.r\n","\n","# Loading the function we have defined in R.\n","r['source']('get_sentimentr.R')\n","\n","# Reading and processing data\n","get_sentimentr_function_r = robjects.globalenv['get_sentimentr_values']"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"-bYu1QKMmMBR"},"outputs":[],"source":["# Test\n","\n","# Convert Python List of Strings to a R vector of characters\n","test_ls = corpus_dt['cdickens_achristmascarol']['text_clean'].to_list()\n","s_v = robjects.StrVector(test_ls)\n","type(s_v)\n","\n","get_sentimentr_function_r(s_v)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"ydWdrTWfxWdE"},"outputs":[],"source":["novels_dt.keys()"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"mJOt0G-kyhJu"},"outputs":[],"source":["text_clean_ct = corpus_dt['dbrown_thedavincicode'].text_clean.isna().sum()\n","text_clean_ct\n","# len(text_clean_ls.isnull())"]},{"cell_type":"markdown","metadata":{"id":"xi-unkmAJLJl"},"source":["**[RE-EXECUTE] May have to re-execute following code cell several times**"]},{"cell_type":"code","source":["%whos dict"],"metadata":{"id":"Fsvo0h0Aq2LC"},"execution_count":null,"outputs":[]},{"cell_type":"code","execution_count":null,"metadata":{"id":"s3EW-6zVlGxW"},"outputs":[],"source":["%%time\n","\n","# NOTE: 8m19s 13 Novels \n","#      16m39s 19 Novels\n","#     -----------------\n","#      24m58s 32 Novels\n","\n","# Call external get_sentimentr::get_sentimentr_values with Python loop over all novels\n","\n","# novels_sentimentr_dt = {}\n","\n","anovel_df = pd.DataFrame()\n","\n","novels_keys_ls = list(corpus_dt.keys())\n","novels_keys_ls.sort()\n","# for i, anovel in enumerate(novels_keys_ls[:19]):\n","for i, anovel in enumerate(novels_keys_ls):  \n","  print(f'\\nProcessing Novel #{i}: {anovel}')\n","  print(f'     {corpus_dt[anovel].shape}')\n","  # Get text_clean as list of strings\n","  text_clean_ls = corpus_dt[anovel]['text_clean'].to_list()\n","\n","  # Convert Python List of Strings to a R vector of characters\n","  # https://rpy2.github.io/doc/v3.0.x/html/generated_rst/pandas.html\n","  s_v = robjects.StrVector(text_clean_ls)\n","  anovel_df_r = get_sentimentr_function_r(s_v)\n","\n","  # Convert rpy2.robjects.vectors.DataFrame to pandas.core.frame.DataFrame\n","  # https://stackoverflow.com/questions/20630121/pandas-how-to-convert-r-dataframe-back-to-pandas \n","  print(f'type(anovel_df_r): {type(anovel_df_r)}')\n","  anovel_df = pd.DataFrame.from_dict({ key : np.asarray(anovel_df_r.rx2(key)) for key in anovel_df_r.names })\n","  print(f'type(anovel_df): {type(anovel_df)}')\n","\n","  # Save Results\n","  # novels_dt[anovel] = anovel_df.copy(deep=True)\n","\n","  corpus_dt[anovel]['sentimentr_jockersrinker'] = anovel_df[anovel]['sentimentr_jockersrinker']\n","  corpus_dt[anovel]['sentimentr_jockers'] = anovel_df[anovel]['sentimentr_jockers']\n","  corpus_dt[anovel]['sentimentr_huliu'] = anovel_df[anovel]['sentimentr_huliu']\n","  corpus_dt[anovel]['sentimentr_nrc'] = anovel_df[anovel]['sentimentr_nrc']\n","  corpus_dt[anovel]['sentimentr_senticnet'] = anovel_df[anovel]['sentimentr_senticnet']\n","  corpus_dt[anovel]['sentimentr_sentiword'] = anovel_df[anovel]['sentimentr_sentiword']\n","  corpus_dt[anovel]['sentimentr_loughran_mcdonald'] = anovel_df[anovel]['sentimentr_loughran_mcdonald']\n","  corpus_dt[anovel]['sentimentr_socal_google'] = anovel_df[anovel]['sentimentr_socal_google']  "]},{"cell_type":"code","source":["cols_sentimentr_ls = [x for x in novels_dt['cdickens_greatexpectations'].columns if 'sentimentr_' in x]\n","cols_sentimentr_ls"],"metadata":{"id":"gE2SroN2z1iV"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["for i, anovel in enumerate(novels_keys_ls):\n","  print(f'Novel #{i}: {anovel}')\n","  for j, amodel in enumerate(cols_sentimentr_ls):\n","    print(f'           Model #{j}: {amodel}')\n","    corpus_dt[anovel][amodel] = novels_dt[anovel][amodel]"],"metadata":{"id":"56HbVjf50Gi8"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["corpus_dt['cdickens_greatexpectations'].head()"],"metadata":{"id":"yTmmNYxMyl11"},"execution_count":null,"outputs":[]},{"cell_type":"code","execution_count":null,"metadata":{"id":"xjtPRa6oD0Iz"},"outputs":[],"source":["len(corpus_dt)"]},{"cell_type":"markdown","metadata":{"id":"KmvRotzK2Ot-"},"source":["## Checkpoint: Save SentimentR Values"]},{"cell_type":"code","source":["# Verify in SentimentArcs Root Directory\n","\n","!pwd\n","print('\\n')\n","!ls"],"metadata":{"id":"83CpiP0VsFOf"},"execution_count":null,"outputs":[]},{"cell_type":"code","execution_count":null,"metadata":{"id":"xorHqcSJsFOf"},"outputs":[],"source":["# Verify Save Destination Subdir: SUBDIR_SENTIMENT_RAW\n","\n","SUBDIR_SENTIMENT_RAW\n","print('\\n')\n","!ls $SUBDIR_SENTIMENT_RAW"]},{"cell_type":"code","source":["corpus_dt.keys()"],"metadata":{"id":"Ts-Nr-F2sFOf"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["corpus_dt['cdickens_achristmascarol']"],"metadata":{"id":"tplx-6u9sFOf"},"execution_count":null,"outputs":[]},{"cell_type":"code","execution_count":null,"metadata":{"id":"pfO2pT74sFOg"},"outputs":[],"source":["# Save sentiment values to subdir_sentiments\n","\n","write_dict_dfs(corpus_dt, out_file='all_7sentimentr.json', out_dir=SUBDIR_SENTIMENT_RAW)"]},{"cell_type":"code","source":["# Verify Dictionary was saved correctly by reading back the *.json datafile\n","\n","test_dt = read_dict_dfs(in_file='all_7sentimentr.json', in_dir=SUBDIR_SENTIMENT_RAW)\n","test_dt.keys()"],"metadata":{"id":"Hwkjn3DAsFOg"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["test_dt['cdickens_greatexpectations'].columns"],"metadata":{"id":"G9Ycl07fsIln"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"8g41AtTk2OuD"},"source":["## Plot SentimentR 7 Models"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"crebkDiI2OuE"},"outputs":[],"source":["#@markdown Select option to save plots:\n","Save_Raw_Plots = True #@param {type:\"boolean\"}\n","\n","Save_Smooth_Plots = True #@param {type:\"boolean\"}\n","Resolution = \"100\" #@param [\"100\", \"300\"]\n","\n"]},{"cell_type":"code","source":["# Get Col Names for all SentimentR Models\n","cols_all_ls = corpus_dt['cdickens_achristmascarol'].columns\n","cols_sentimentr_ls = [x for x in cols_all_ls if 'sentimentr_' in x]\n","cols_sentimentr_ls"],"metadata":{"id":"5Y8YMcussjxW"},"execution_count":null,"outputs":[]},{"cell_type":"code","execution_count":null,"metadata":{"id":"TW2i22s6tCaH"},"outputs":[],"source":["novels_dt['cdickens_achristmascarol'][0]"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"as2x7TaotCaH"},"outputs":[],"source":["SUBDIR_PLOTS"]},{"cell_type":"code","source":["novels_dt['cdickens_greatexpectations']"],"metadata":{"id":"RighiFTK1pC4"},"execution_count":null,"outputs":[]},{"cell_type":"code","execution_count":null,"metadata":{"id":"Aq3isNKvtCaI"},"outputs":[],"source":["# Verify 7 SentimentR Models with Plots\n","\n","\n","for i, anovel in enumerate(list(corpus_dt.keys())):\n","\n","  print(f'Novel #{i}: {novels_dt[anovel][0]}')\n","\n","  # Raw Sentiments \n","  fig = corpus_dt[anovel][cols_sentimentr_ls].plot(title=f'{novels_dt[anovel][0]}\\n SentimentR 7 Models: Raw Sentiments', alpha=0.3)\n","  plt.show();\n","\n","  if Save_Raw_Plots:\n","    plt.savefig(f'{SUBDIR_PLOTS}plot_sentimentr_raw_{anovel}_dpi{Resolution}.png', dpi=int(Resolution))\n","\n","  \n","  # Smoothed Sentiments (SMA 10%)\n","  # novel_sample = 'cdickens_achristmascarol'\n","  win_10per = int(corpus_dt[anovel].shape[0] * 0.1)\n","  corpus_dt[anovel][cols_sentimentr_ls].rolling(win_10per, center=True, min_periods=0).mean().plot(title=f'{novels_dt[anovel][0]}\\n SentimentR 7 Models: Smoothed Sentiments (SMA 10%)', alpha=0.3)\n","  plt.show();\n","\n","  if Save_Smooth_Plots:\n","    plt.savefig(f'{SUBDIR_PLOTS}plot_sentimentr_smooth10sma_{anovel}_dpi{Resolution}.png', dpi=int(Resolution))\n"]},{"cell_type":"markdown","metadata":{"id":"YC3xCnGF22td"},"source":["# **END OF NOTEBOOK**"]},{"cell_type":"markdown","metadata":{"id":"Z2ADWh-aaImU"},"source":["---"]}],"metadata":{"colab":{"collapsed_sections":["EA1yTaY_9Qod","7dPPrZwyIIze"],"name":"sentiment_arcs_2_syuzhetr4_sentimentr7.ipynb","toc_visible":true,"provenance":[]},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"name":"python"}},"nbformat":4,"nbformat_minor":0}