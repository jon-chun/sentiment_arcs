{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"sentiment_arcs_sentiments_rpy2.ipynb","provenance":[],"collapsed_sections":[],"toc_visible":true,"machine_shape":"hm"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"markdown","metadata":{"id":"AtxyCnlCcAi1"},"source":["# **Compute Sentiment from 4 SyuzhetR and 7 SentimentR Models**\n","\n","* https://www.youtube.com/watch?v=U3ByGh8RmSc\n","\n","* https://github.com/ttimbers/intro-to-reticulate\n","\n","[Use R on Google Colab!](https://colab.research.google.com/notebook#create=true&language=r)"]},{"cell_type":"markdown","source":["# Configure Notebook"],"metadata":{"id":"5WXg7SfvtUc_"}},{"cell_type":"code","source":["from IPython.core.interactiveshell import InteractiveShell\n","InteractiveShell.ast_node_interactivity = \"all\""],"metadata":{"id":"sVakzwb-tUUY"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["# Connect to Google gDrive\n","\n","* https://towardsdatascience.com/access-google-drive-using-google-colab-running-an-r-kernel-3736db7835\n"],"metadata":{"id":"4ocjOFKU1329"}},{"cell_type":"code","source":["from google.colab import drive\n","drive.mount('/gdrive')\n","%cd /gdrive"],"metadata":{"id":"nyadxlbZmnV9"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["%cd ./MyDrive/research/2022/sentiment_arcs/notebooks/"],"metadata":{"id":"uqaDywYx2bvO"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["!ls"],"metadata":{"id":"VKxZdKyTmsgl"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["# Define Globals"],"metadata":{"id":"aG4DtHQ1sgj0"}},{"cell_type":"code","source":["# CUSTOMIZE: define subdirectory paths\n","\n","# Input subdirectories\n","subdir_novels = '../in1_novels/'\n","subdir_preprocessed = '../in2_preprocessed_text/'\n","subdir_sentiments = '../in3_sentiments/'\n","\n","# data_raw_subdir  = './data/sentiments_raw/'\n","# data_clean_subdir  = './data/sentiments_clean/'\n","# novels_subdir = './in1_novels/'\n","# lexicons_subdir = './lexicons/'\n","\n","# Output subdirectories\n","subdir_plots_arcs = '../out1_arcs/'\n","subdir_plots_cruxes = '../out2_cruxes/'\n","\n","# plots_subdir = './out1_arcs/'\n","# plots_subdir = '../book_shape_of_stories/'\n","\n","# crux_subdir = './crux/'\n","# code_subdir  = './sentiment_arcs/sentiment_arcs/'"],"metadata":{"id":"ammhnysEQdm5"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Consider requiring this as header line in source text files so all data in one place\n","\n","novels_dt = {\n","  'cdickens_achristmascarol':['A Christmas Carol by Charles Dickens ',1843,1399],\n","  'cdickens_greatexpectations':['Great Expectations by Charles Dickens' ,1861, 7230],\n","  'dbrown_thedavincicode':['The Da Vinci Code by Dan Brown', 2003, 9475],\n","  'ddefoe_robinsoncrusoe':['Robinson Crusoe by Daniel Defoe',1719, 2280],\n","  'eljames_fiftyshadesofgrey':['Fifty Shades of Grey by E.L. James', 2011, 8184],\n","  'emforster_howardsend':['Howards End by E.M. Forester', 1910, 8999],\n","  'fbaum_thewonderfulwizardofoz':['The Wonderful Wizard of Oz by Frank Baum', 1850, 2238],\n","  'fdouglass_narrativelifeofaslave':['Narrative of the life of Frederick Douglass, an American Slave by Frederick Douglass', 1845, 1688],\n","  'fscottfitzgerald_thegreatgatsby':['The Great Gatsby by F. Scott Fitzgerald', 1925, 2950],\n","  'geliot_middlemarch':['Middlemarch by George Eliot', 1871, 10373],\n","  'hjames_portraitofalady':['The Portrait of a Lady by Henry James', 1881, 13258],\n","  'homer-ewilson_odyssey':['The Odyssey by Homer (trans Emily Wilson)', 2018, 6814],\n","  'imcewan_machineslikeme':['Machines Like Me by Ian McEwan', 2019, 6448],\n","  'jausten_prideandprejudice':['Pride and Prejudice by Jane Austen', 1813, 5891],\n","  'jconrad_heartofdarkness':['Heart of Darkness by Joseph Conrad', 1902, 1619],\n","  'jjoyce_portraitoftheartist':['A Portrait of the Artist as a Young Man by James Joyce', 2016, 5584],\n","  'jkrowling_1sorcerersstone':['Harry Potter and the Sorcererâ€™s Stone by J.K. Rowling', 1997, 5488],\n","  'jkrowling_4gobletoffire':['Harry Potter and the Goblet of Fire by J.K. Rowling', 2000, 6809],\n","  'jkrowling_4gobletoffire_screenplay':['Screenplay for Harry Potter and the Goblet of Fire by J.K. Rowling and Steve Klovesand J.', 2005, 582],\n","  # 'jkrowling_7deathlyhollows':['Harry Potter and the Deathly Hallows by J.K. Rowling', 2007, 6588],\n","  'kvonnegut_slaughterhousefive':['Slaughterhouse Five by Kurt Vonnegut', 1969, 5607],\n","  'mproust-mtreharne_3guermantesway':['In Search of Lost Time, Vol 3: The Guermantes Way by Marcel Proust', 1920, 8388],\n","  'mshelley_frankenstein':['Frankenstein by Mary Shelly', 1818, 3282],\n","  'mtwain_huckleberryfinn':['Huckleberry Finn by Mark Twain', 1884, 5775],\n","  'pjackson_thelightningthief':[\"The Lightning Thief by Peter Jackson\", 2005, 8277],\n","  'staugustine_confessions9end':['Confessions (Books 1-9) by St. Augustine', 400, 3673],\n","  'tmorrison_beloved':['Beloved by Toni Morrison', 1987, 7102],\n","  'vnabokov_palefire':['Pale Fire by Viktor Nabokov', 1962, 2984],\n","  'vwoolf_mrsdalloway':['Mrs. Dalloway by Virginia Woolf', 1925, 3647],\n","  'vwoolf_orlando':['Orlando by Virginia Woolf', 1928, 2,992],\n","  'vwoolf_thewaves':['The Waves by Virginia Woolf', 1931, 3919],\n","  'vwoolf_tothelighthouse':['To The Lighthouse by Virginia Woolf', 1927, 3403],\n","  'wgolding_lordoftheflies':['Lord of the Flies by William Golding', 1954, 5441]\n","}"],"metadata":{"id":"9qwPwHNuP0Uk"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["# R Libraries: Install and Load"],"metadata":{"id":"uNwIAUc6uDdo"}},{"cell_type":"code","source":["# !pip install rpy2"],"metadata":{"id":"p05_XBc6uBrK"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# !pip install -U rpy2"],"metadata":{"id":"83BAG8HPS0-f"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# enables the %%R magic, not necessary if you've already done this\n","%load_ext rpy2.ipython"],"metadata":{"id":"x4zeGVURuJ9r"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# %reload_ext rpy2.ipython"],"metadata":{"id":"Epid7gshS8k3"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["%%time \n","%%capture \n","%%R\n","\n","# Install Syuzhet.R and Sentiment.R\n","\n","install.packages(c('syuzhet', 'sentimentr', 'tidyverse', 'lexicon'))\n","\n","library(syuzhet)\n","library(sentimentr)\n","library(tidyverse)\n","library(lexicon)\n","\n","# NOTE:   17s\n","#       1m05s"],"metadata":{"id":"DgF1pBDQuVKY"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# %reload_ext rpy2.ipython"],"metadata":{"id":"wTDXivt_TPQD"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["import rpy2.robjects as robjects\n","from rpy2.robjects.packages import importr"],"metadata":{"id":"XUmxULxnKqQb"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["%%R\n","\n","R.version.string"],"metadata":{"id":"StqQYI0Aq8mE"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["%%R\n","\n","sessionInfo()"],"metadata":{"id":"fQTZyrZzH-XZ"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["%%R\n","\n","Sys.getenv"],"metadata":{"id":"dioCyXqZABym"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["# Python Libraries: Install"],"metadata":{"id":"If55aLQYsk_K"}},{"cell_type":"code","source":["import numpy as np\n","import pandas as pd\n","import matplotlib.pyplot as plt\n","import seaborn as sns\n","\n","%matplotlib inline"],"metadata":{"id":"oVNT7dGQsmw3"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["from glob import glob\n","import copy\n","import json"],"metadata":{"id":"emaLq2QGn0rw"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Show all default settings\n","\n","# plt.rcParams # all\n","# plt.rcParams[\"figure.figsize\"]\n","\n","# Default figure size\n","fig_size = plt.rcParams.get('figure.figsize')\n","\n","print(\" The Default figure size in jupyter notebook is: \", fig_size)"],"metadata":{"id":"Yp2uBUPrAsPI"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Set matplotlib plot figure.figsize\n","\n","new_plt_size = plt.rcParams[\"figure.figsize\"]=(20,10)\n","\n","print(\" New figure size: \",new_plt_size)"],"metadata":{"id":"M5A41pzM9aJY"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["# Python Utility Functions"],"metadata":{"id":"X229IbToHwa2"}},{"cell_type":"code","source":["# Utility functions to read/write nested Dictionary (key=novel) of DataFrames (Cols = Model Sentiment Series) \n","\n","def write_dict_dfs(adict, out_file='sentiments.json', out_dir=subdir_sentiments):\n","  '''\n","  Given a Dictionary of DataFrames and optional output filename and output directory\n","  Write as nested json file\n","  '''\n","\n","  # convert dataframes into dictionaries\n","  data_dict = {\n","      key: adict[key].to_dict(orient='records') \n","      for key in adict.keys()\n","  }\n","\n","  # write to disk\n","  out_fullpath = f'{out_dir}{out_file}'\n","  print(f'Saving file to: {out_fullpath}')\n","  with open(out_fullpath, 'w') as fp:\n","    json.dump(\n","      data_dict, \n","      fp, \n","      indent=4, \n","      sort_keys=True\n","    )\n","\n","  return \n","\n","def read_dict_dfs(in_file='sentiments.json', in_dir=subdir_sentiments):\n","  '''\n","  Given a Dictionary of DataFrames and optional output filename and output directory\n","  Read nested json file into Dictionary of DataFrames\n","  '''\n","\n","  # read from disk\n","  in_fullpath = f'{in_dir}{in_file}'\n","  with open(in_fullpath, 'r') as fp:\n","      data_dict = json.load(fp)\n","\n","  # convert dictionaries into dataframes\n","  all_dt = {\n","      key: pd.DataFrame(data_dict[key]) \n","      for key in data_dict\n","  }\n","\n","  return all_dt"],"metadata":{"id":"HqZri_3GHvqc"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["# Read all Preprocessed Novels"],"metadata":{"id":"fys3dkJSB656"}},{"cell_type":"code","source":["# Create a List (preprocessed_ls) of all preprocessed text files\n","\n","try:\n","    preprocessed_ls = glob(f'{subdir_preprocessed}*.csv')\n","    preprocessed_ls = [x.split('/')[-1] for x in preprocessed_ls]\n","    preprocessed_ls = [x.split('.')[0] for x in preprocessed_ls]\n","except IndexError:\n","    raise RuntimeError('No csv file found')\n","\n","print('\\n'.join(preprocessed_ls))\n","print('\\n')\n","print(f'Found {len(preprocessed_ls)} Preprocessed files in {subdir_preprocessed}')"],"metadata":{"id":"2ClL4-1Gqe7g"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Read all preprocessed text files into master DataFrame (novels_all_dt)\n","\n","novels_all_dt = {}\n","\n","for i,anovel in enumerate(preprocessed_ls):\n","  print(f'Processing #{i}: {anovel}...')\n","  afile_fullpath = f'{subdir_preprocessed}{anovel}.csv'\n","  print(f'               {afile_fullpath}')\n","  anovel_df = pd.read_csv(afile_fullpath)\n","  novels_all_dt[anovel] = anovel_df"],"metadata":{"id":"S4CqJQY9rNRw"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Verify the novels read into master Dictionary of DataFrames\n","\n","novels_all_dt.keys()\n","print('\\n')\n","print(f'There were {len(novels_all_dt)} preprocessed novels read into the Dict novels_all_dt')"],"metadata":{"id":"QHLt5o78tJyR"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Check if there are any Null strings in the text_clean columns\n","\n","for i, anovel in enumerate(list(novels_all_dt.keys())):\n","  print(f'\\nNovel #{i}: {anovel}')\n","  nan_ct = novels_all_dt[anovel].text_clean.isna().sum()\n","  if nan_ct > 0:\n","    print(f'      {nan_ct} Null strings in the text_clean column')"],"metadata":{"id":"0JI2z5wCz8zz"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Fill in all the Null value of text_clean with placeholder 'empty_string'\n","\n","for i, anovel in enumerate(list(novels_all_dt.keys())):\n","  # print(f'Novel #{i}: {anovel}')\n","  # Fill all text_clean == Null with 'empty_string' so sentimentr::sentiment doesn't break\n","  novels_all_dt[anovel][novels_all_dt[anovel].text_clean.isna()] = 'empty_string'"],"metadata":{"id":"mgLyDNrYzTuF"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Verify one DataFrame in the master Dictionary\n","\n","novels_all_dt['dbrown_thedavincicode'].head()"],"metadata":{"id":"O7gE08b_rNPH"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["**[SKIP] to next section**"],"metadata":{"id":"VFqKoB_q83u_"}},{"cell_type":"code","source":["%%R -i df -w 5 -h 5 --units in -r 200\n","# import df from global environment\n","# make default figure size 5 by 5 inches with 200 dpi resolution\n","\n","install.packages(\"ggplot2\", repos='http://cran.us.r-project.org', quiet=TRUE)\n","library(ggplot2)\n","ggplot(df, aes(x=cups_of_coffee, y=productivity)) + geom_line()"],"metadata":{"id":"_YuUeV7crNL7"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["from pathlib import Path"],"metadata":{"id":"YxVnBl03p-tx"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["!python --version"],"metadata":{"id":"rt3pm4DaqK2j"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["if (path := next(Path(subdir_preprocessed).glob(\"*.csv\"), None)) is None:\n","    print(\"No .csv file present!\")\n","else:\n","    print(path)"],"metadata":{"id":"3XHliBmEqAP1"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["try:\n","    path_ls = next(Path(subdir_preprocessed).glob(\"*.csv\"))\n","except StopIteration:\n","    raise RuntimeError(\"No .csv file present!\")\n","\n","path_ls"],"metadata":{"id":"y5Bwd9T-qO6s"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["import pathlib\n","[p for p in pathlib.Path('../in2_preprocessed_text/').iterdir() if p.is_file()]"],"metadata":{"id":"5w00T17Npofu"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["# [SKIP] SyuzhetR Library\n","\n","* https://github.com/mjockers/syuzhet\n","\n","* https://cran.r-project.org/web/packages/syuzhet/index.html"],"metadata":{"id":"7mbGS9RTEAYH"}},{"cell_type":"code","source":["preprocessed_ls"],"metadata":{"id":"lh6tVQqBv8MK"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["novels_all_dt['cdickens_achristmascarol']"],"metadata":{"id":"c7z_LBGuv1g1"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["import rpy2.robjects as robjects\n","a = robjects.r('list(foo=\"barbat\", fizz=123)')"],"metadata":{"id":"PtfEJlPpwa3p"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["test_df = novels_all_dt['cdickens_achristmascarol']\n","test_df.head()"],"metadata":{"id":"SCFT3VOGw4bw"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["%%R -i test_df -o get_syuzhetr_syuzhet\n","\n","get_syuzhetr_syuzhet <- function(test_df) {\n","    sentiment_syuzhet <- get_sentiment(test_df$text_clean, method='syuzhet')\n","}"],"metadata":{"id":"7J4-5fZ4xLHk"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["%%R -i test_df\n","get_syuzhetr_syuzhet(test_df)"],"metadata":{"id":"E2o2FWpyxxd5"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["%%R -i test_df\n","\n","require(dplyr)\n","glimpse(test_df)"],"metadata":{"id":"qUOalyy3vqUd"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["%%R -i novels_all_dt -o novels_all_dt\n","# import df from global environment\n","# make default figure size 5 by 5 inches with 200 dpi resolution\n","\n","install.packages(\"ggplot2\", repos='http://cran.us.r-project.org', quiet=TRUE)\n","library(ggplot2)\n","ggplot(df, aes(x=cups_of_coffee, y=productivity)) + geom_line()"],"metadata":{"id":"08w0fMe4vVwZ"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":[""],"metadata":{"id":"rvpaPjQavVtV"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["from rpy2.robjects.packages import importr\n","base = importr('base')\n","stats = importr('stats')\n","graphics = importr('graphics')\n","\n","plot = graphics.plot\n","# rnorm = stats.rnorm\n","# plot(rnorm(100), ylab=\"random\")"],"metadata":{"id":"aTp-oEbxya44"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["# Get Sentiments using 4 SyuzhetR Models on Every Novel"],"metadata":{"id":"GuoJERbI0wEJ"}},{"cell_type":"code","source":["# Make a copy of DataFrame for 4 SyuzhetR Models\n","\n","novels_syuzhetr_dt = copy.deepcopy(novels_all_dt)"],"metadata":{"id":"R2dUPEa-_mkQ"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["## Option (a): Read Previously Computed SyuzhetR Values from Datafiles"],"metadata":{"id":"99hi2_XPomrT"}},{"cell_type":"code","source":["# Read in Saved SyuzhetR Datafile from subdir_sentiments/all_4syuzhetr.json\n","\n","novels_syuzhetr_dt = read_dict_dfs('all_4syuzhetr.json')\n","novels_syuzhetr_dt.keys()"],"metadata":{"id":"8fNpTykSorBy"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Verify all the Novels have 4 Syuzhet Model Values\n","\n","for i, anovel in enumerate(list(novels_syuzhetr_dt.keys())):\n","  print(f'Novel #{i}: {anovel}')\n","  novels_syuzhetr_dt[anovel].drop(columns=['Unnamed: 0'], inplace=True)\n","  print(f'      df.shape: {novels_syuzhetr_dt[anovel].shape}')"],"metadata":{"id":"AV2P9VeQpiY2"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Verify DataFrame for test novel\n","\n","novel_str = 'cdickens_achristmascarol'\n","novels_syuzhetr_dt[novel_str].head()"],"metadata":{"id":"IC7BnYPwpBQ5"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["## Option (b): Compute New SyuzhetR Values"],"metadata":{"id":"ZMS53E-CorWs"}},{"cell_type":"code","source":["%whos dict\n"],"metadata":{"id":"OCtmtzYC_yqU"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["novels_all_dt['cdickens_achristmascarol']['text_clean'].to_list()"],"metadata":{"id":"h94o_8qOAINH"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Compute Sentiments from all 4 Syuzhet Models applied to all 32 Novels (4 x 32 = 128 runs)\n","\n","# NOTE: 9m45s 23:30 on 20220114 Colab Pro (33 Novels)\n","\n","# base = importr('base')\n","syuzhet = importr('syuzhet')\n","\n","# base.rank(0, na_last = True)\n","novels_keys_ls = list(novels_all_dt.keys())\n","novels_keys_ls.sort()\n","for i, anovel in enumerate(novels_keys_ls):\n","  print(f'Processing Novel #{i}: {anovel}...')\n","  novels_syuzhetr_dt[anovel]['syuzhetr_syuzhet'] = syuzhet.get_sentiment(novels_syuzhetr_dt[anovel]['text_clean'].to_list(), method='syuzhet')\n","  novels_syuzhetr_dt[anovel]['syuzhetr_bing'] = syuzhet.get_sentiment(novels_syuzhetr_dt[anovel]['text_clean'].to_list(), method='bing')\n","  novels_syuzhetr_dt[anovel]['syuzhetr_afinn'] = syuzhet.get_sentiment(novels_syuzhetr_dt[anovel]['text_clean'].to_list(), method='afinn')\n","  novels_syuzhetr_dt[anovel]['syuzhetr_nrc'] = syuzhet.get_sentiment(novels_syuzhetr_dt[anovel]['text_clean'].to_list(), method='nrc')"],"metadata":{"id":"qDAb6bHqya1-"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["### Save Checkpoint"],"metadata":{"id":"SR9X7JGEqkMV"}},{"cell_type":"code","source":["# Verify save_to directory\n","\n","subdir_sentiments\n","print('\\n')\n","!ls $subdir_sentiments"],"metadata":{"id":"xFJ0Sj45_Hba"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Save sentiment values to subdir_sentiments\n","\n","write_dict_dfs(novels_syuzhetr_dt, out_file='all_4syuzhetr.json', out_dir=subdir_sentiments)"],"metadata":{"id":"0-Kzyc3FEZ71"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["## Plot SyuzhetR 4 Models"],"metadata":{"id":"nbQbIO9iqHUo"}},{"cell_type":"code","source":["#@markdown Select option to save plots:\n","Save_Raw_Plots = True #@param {type:\"boolean\"}\n","\n","Save_Smooth_Plots = True #@param {type:\"boolean\"}\n","Resolution = \"300\" #@param [\"100\", \"300\"]\n","\n"],"metadata":{"id":"wxfVwdKvudRa"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["syuzhetr_cols_ls = novels_syuzhetr_dt['cdickens_achristmascarol'].columns\n","syuzhetr_models_ls = [x for x in syuzhetr_cols_ls if 'syuzhetr_' in x]\n","syuzhetr_models_ls\n","\n","# OR\n","\n","# syuzhetr_models_ls = ['syuzhetr_afinn', 'syuzhetr_bing', 'syuzhetr_nrc', 'syuzhetr_syuzhet']"],"metadata":{"id":"Y5TXvTTAsPur"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["novels_dt['cdickens_achristmascarol'][0]"],"metadata":{"id":"bzMQ3Sl8trUw"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["subdir_plots_arcs"],"metadata":{"id":"ET8xiEY6vrCT"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Verify 4 Sentiment Models from Syuzhet for sample Novel\n","\n","for i, anovel in enumerate(list(novels_all_dt.keys())):\n","\n","  # Raw Sentiments \n","  fig = novels_syuzhetr_dt[anovel][syuzhetr_models_ls].plot(title=f'{novels_dt[anovel][0]}\\n SyuzhetR 4 Models: Raw Sentiments', alpha=0.3)\n","  plt.show()\n","\n","  if Save_Raw_Plots:\n","    plt.savefig(f'{subdir_plots_arcs}plot_syuzhetr_raw_{anovel}_dpi{Resolution}.png', dpi=int(Resolution))\n","\n","  \n","  # Smoothed Sentiments (SMA 10%)\n","  # novel_sample = 'cdickens_achristmascarol'\n","  win_10per = int(novels_syuzhetr_dt[anovel].shape[0] * 0.1)\n","  novels_syuzhetr_dt[anovel][syuzhetr_models_ls].rolling(win_10per, center=True, min_periods=0).mean().plot(title=f'{novels_dt[anovel][0]}\\n SyuzhetR 4 Models: Smoothed Sentiments (SMA 10%)', alpha=0.3)\n","  plt.show()\n","\n","  if Save_Smooth_Plots:\n","    plt.savefig(f'{subdir_plots_arcs}plot_syuzhetr_smooth10sma_{anovel}_dpi{Resolution}.png', dpi=int(Resolution))\n"],"metadata":{"id":"5lkWMeKU2BnK"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["# Get Sentiments using 7 SentimentR Models on Every Novel"],"metadata":{"id":"yl8og94l09WX"}},{"cell_type":"code","source":["# Make a copy of DataFrame for 7 SentimentR Models\n","\n","novels_sentimentr_dt = copy.deepcopy(novels_all_dt)\n"],"metadata":{"id":"zRjNNFmd_idg"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# import rpy2"],"metadata":{"id":"Zf2gICABTlkX"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# dir(rpy2.robjects)"],"metadata":{"id":"rUR_QjvvSuY7"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# !pip install -U rpy2"],"metadata":{"id":"LCcysg5DMC8V"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# dir(lexicon)"],"metadata":{"id":"ynYiJAyER13L"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":[""],"metadata":{"id":"A0QbPaV0R9mz"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# from rpy2.robjects.packages import importr\n","\n","# NOTE: 1m22s for 1 out of (7x32 = 224)\n","\n","sentimentr = importr('sentimentr')\n","lexicon = importr('lexicon')\n","\n","novels_keys_ls = list(novels_all_dt.keys())\n","# lexicon_robj = lexicon.hash_sentiment_huliu\n","for i, anovel in enumerate(novels_keys_ls[:1]):\n","  print(f'Processing Novel #{i}: {anovel}...')\n","  print( '                 jockers_rinker')\n","  novels_all_dt[anovel]['sentimentr_jockersrinker'] = novels_all_dt[anovel]['text_clean'].apply(lambda x: sentimentr.sentiment(x, polarity_dt=lexicon.hash_sentiment_jockers_rinker)) # polarity_dt=lexicon.hash_sentiment_jockers_rinker))\n","\n","  print( '                 jockers')  # 1m20s\n","  ## novels_all_dt[anovel]['sentimentr_jockers'] = novels_all_dt[anovel]['text_clean'].apply(lambda x: sentimentr.sentiment(x, polarity_dt=lexicon.hash_sentiment_jockers)) # polarity_dt=lexicon.hash_sentiment_jockers_rinker))\n","\n","  # lexicon_robj = lexicon.hash_sentiment_huliu\n","  print( '                 huliu')\n","  # novels_all_dt[anovel]['sentimentr_huliu'] = novels_all_dt[anovel]['text_clean'].apply(lambda x: sentimentr.sentiment(x, polarity_dt=lexicon.hash_sentiment_huliu)) # lexicon_robj)) # polarity_dt=lexicon.hash_sentiment_huliu))\n","\n","  # lexicon_robj = lexicon.hash_sentiment_nrc\n","  print( '                 nrc')\n","  # novels_all_dt[anovel]['sentimentr_nrc'] = novels_all_dt[anovel]['text_clean'].apply(lambda x: sentimentr.sentiment(x, polarity_dt=lexicon_robj)) # polarity_dt=lexicon.hash_sentiment_nrc))\n","\n","  print( '                 senticnet')\n","  # novels_all_dt[anovel]['sentimentr_senticnet'] = novels_all_dt[anovel]['text_clean'].apply(lambda x: sentimentr.sentiment(x, polarity_dt=lexicon_robj)[[3]]) # polarity_dt=lexicon.hash_sentiment_senticnet))\n","\n","  print( '                 sentiword')\n","  # novels_all_dt[anovel]['sentimentr_sentiword'] = novels_all_dt[anovel]['text_clean'].apply(lambda x: sentimentr.sentiment(x, polarity_dt=lexicon_robj)) # polarity_dt=lexicon.hash_sentiment_sentiword))\n","\n","  print( '                 loughran_mcdonald')\n","  # novels_all_dt[anovel]['sentimentr_loughran_mcdonald'] = novels_all_dt[anovel]['text_clean'].apply(lambda x: sentimentr.sentiment(x, polarity_dt=lexicon_robj)) # polarity_dt=lexicon.hash_sentiment_loughran_mcdonald))\n","\n","  # test_sent = 'I love lint very much'\n","  # test_str = sentimentr.sentiment(test_sent)\n","  # print(f'SentimentR: {test_str} for \\n            {test_sent}')\n","  # novels_all_dt[anovel]['sentimentr_jockersrinker'] = sentimentr.sentiment(novels_all_dt[anovel]['text_clean'].to_list())"],"metadata":{"id":"WWHxJZ7F4MEc"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["novels_all_dt['cdickens_achristmascarol'].head()"],"metadata":{"id":"g8Dh62S-Kurp"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["from rpy2.robjects.packages import importr\n","\n","sentiment = importr('sentimentr')\n","\n","novels_keys_ls = list(novels_all_dt.keys())\n","for i, anovel in enumerate(novels_keys_ls[:1]):\n","  print(f'Processing Novel #{i}: {anovel}...')\n","  novels_all_dt[anovel]['sentimentr_jockersrinker'] = sentiment(novels_all_dt[anovel]['text_clean'].to_list(), polarity_dt=lexicon::hash_sentiment_jockers_rinker, \n","                                                                hypen=\"\", amplifier_weight=0.8, n_before=5, n_after=2,\n","                                                                adversative_weight=0.25, neutral_nonverb_like = FALSE, missing_value = 0)\n"],"metadata":{"id":"mLy5xJiP09MF"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":[""],"metadata":{"id":"Uzg0KaacIb9G"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["SentimentAnalysis <- apply(analyzeSentiment(s_v)[c('SentimentGI', 'SentimentLM', 'SentimentQDAP') ], 2, round, 2)\n","colnames(SentimentAnalysis) <- gsub('^Sentiment', \"SA_\", colnames(SentimentAnalysis))"],"metadata":{"id":"WnOlIGM4IcH7"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["sentimentr_jockersrinker <- sentiment(s_v, polarity_dt=lexicon::hash_sentiment_jockers_rinker, \n","                                      hypen=\"\", amplifier.weight=0.8, n.before=5, n.after=2,\n","                                      adversative.weight=0.25, neutral.nonverb.like = FALSE, missing_value = 0)"],"metadata":{"id":"gnfGTAprIcH8"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["sentimentr_jockersrinker"],"metadata":{"id":"Psp00oCsIcH9"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":[""],"metadata":{"id":"GoiVsgabT0Yc"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["%%R\n","\n","sessionInfo()"],"metadata":{"id":"vV7axnjlT0Vh"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["test_ls = novels_all_dt['cdickens_achristmascarol']['text_clean'].to_list()\n","len(test_ls)"],"metadata":{"id":"4uYnoeutUysx"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["import rpy2.robjects as robjects\n","from rpy2.robjects.packages import importr"],"metadata":{"id":"1-g5y8jOVm_X"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["s_v = robjects.StrVector(test_ls)\n","type(s_v)\n","\n","lexicon_name = lexicon::hash_sentiment_jockers_rinker"],"metadata":{"id":"8T9yUuzYVd42"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["novels_sentimentr_df = pd.DataFrame()"],"metadata":{"id":"693-R-KDdN3s"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":[""],"metadata":{"id":"XryAg_4Ghrvq"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["novels_roots_ls = list(novels_all_dt.keys())"],"metadata":{"id":"gZaVaswhhcjt"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["for i,anovel_root in enumerate(novels_roots_ls):\n","  print(f'Novel #{i}: {anovel_root}')\n","  print(f'     {novels_all_dt[anovel_root].shape}')"],"metadata":{"id":"-6tCnJWyiCCG"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["%%R -i novels_roots_ls\n","\n","# novels_key_ls = c('cdickens_achristmascarol')\n","\n","for(i in 1:length(novels_roots_ls)) {\n","  {print(novels_roots_ls[i])}\n","}"],"metadata":{"id":"SEW6IR8aghjz"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["## Option (a): Read Previous Computed SentimentR Values from DataFile"],"metadata":{"id":"_N9zLYYpxq0f"}},{"cell_type":"code","source":["# Read in Saved SyuzhetR Datafile from subdir_sentiments/all_4syuzhetr.json\n","\n","novels_sentimentr_dt = read_dict_dfs('all_7sentimentr.json')\n","novels_sentimentr_dt.keys()"],"metadata":{"id":"nacTYi6ax4k5"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Verify all the Novels have 4 Syuzhet Model Values\n","\n","for i, anovel in enumerate(list(novels_sentimentr_dt.keys())):\n","  print(f'Novel #{i}: {anovel}')\n","  novels_synovels_sentimentr_dtuzhetr_dt[anovel].drop(columns=['Unnamed: 0'], inplace=True)\n","  print(f'      df.shape: {novels_sentimentr_dt[anovel].shape}')"],"metadata":{"id":"AXsPH_3Vx4k8"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Verify DataFrame for test novel\n","\n","novel_str = 'cdickens_achristmascarol'\n","novels_sentimentr_dt[novel_str].head()"],"metadata":{"id":"QjPDtuaMx4k9"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["## Option (b): Compute New SentimentR Values\n","\n","Call function in external get_sentimentr.R from within Python Loop\n","\n","* https://medium.com/analytics-vidhya/calling-r-from-python-magic-of-rpy2-d8cbbf991571\n","\n","* https://rpy2.github.io/doc/v3.0.x/html/generated_rst/pandas.html"],"metadata":{"id":"AQeJ5VtmkX3I"}},{"cell_type":"code","source":["%%file get_sentimentr.R\n","\n","library(sentimentr)\n","library(lexicon)\n","\n","get_sentimentr_values <- function(s_v) {\n","  \n","  print('Processing sentimentr_jockersrinker')\n","  sentimentr_jockersrinker <- sentiment(s_v, polarity_dt=lexicon::hash_sentiment_jockers_rinker, \n","                                        hypen=\"\", amplifier.weight=0.8, n.before=5, n.after=2,\n","                                        adversative.weight=0.25, neutral.nonverb.like = FALSE, missing_value = 0)\n","\n","  print('Processing sentimentr_jockers')\n","  sentimentr_jockers <- sentiment(s_v, polarity_dt=lexicon::hash_sentiment_jockers, \n","                                        hypen=\"\", amplifier.weight=0.8, n.before=5, n.after=2,\n","                                        adversative.weight=0.25, neutral.nonverb.like = FALSE, missing_value = 0)\n","\n","  print('Processing sentimentr_huliu')\n","  sentimentr_huliu <- sentiment(s_v, polarity_dt=lexicon::hash_sentiment_huliu, \n","                                        hypen=\"\", amplifier.weight=0.8, n.before=5, n.after=2,\n","                                        adversative.weight=0.25, neutral.nonverb.like = FALSE, missing_value = 0)\n","\n","  print('Processing sentimentr_nrc')\n","  sentimentr_nrc <- sentiment(s_v, polarity_dt=lexicon::hash_sentiment_nrc, \n","                                        hypen=\"\", amplifier.weight=0.8, n.before=5, n.after=2,\n","                                        adversative.weight=0.25, neutral.nonverb.like = FALSE, missing_value = 0)\n","\n","  print('Processing sentimentr_senticnet')\n","  sentimentr_senticnet <- sentiment(s_v, polarity_dt=lexicon::hash_sentiment_senticnet, \n","                                        hypen=\"\", amplifier.weight=0.8, n.before=5, n.after=2,\n","                                        adversative.weight=0.25, neutral.nonverb.like = FALSE, missing_value = 0)\n","\n","  print('Processing sentimentr_sentiword')\n","  sentimentr_sentiword <- sentiment(s_v, polarity_dt=lexicon::hash_sentiment_sentiword, \n","                                        hypen=\"\", amplifier.weight=0.8, n.before=5, n.after=2,\n","                                        adversative.weight=0.25, neutral.nonverb.like = FALSE, missing_value = 0)\n","\n","  print('Processing sentimentr_loughran_mcdonald')\n","  sentimentr_loughran_mcdonald <- sentiment(s_v, polarity_dt=lexicon::hash_sentiment_loughran_mcdonald, \n","                                        hypen=\"\", amplifier.weight=0.8, n.before=5, n.after=2,\n","                                        adversative.weight=0.25, neutral.nonverb.like = FALSE, missing_value = 0)\n","\n","  print('Processing sentimentr_socal_google')\n","  sentimentr_socal_google <- sentiment(s_v, polarity_dt=lexicon::hash_sentiment_socal_google, \n","                                        hypen=\"\", amplifier.weight=0.8, n.before=5, n.after=2,\n","                                        adversative.weight=0.25, neutral.nonverb.like = FALSE, missing_value = 0)\n","\n","  anovel_sentimentr_df <- data.frame('text_clean' = s_v,\n","                                'sentimentr_jockersrinker' = sentimentr_jockersrinker$sentiment,\n","                                'sentimentr_jockers' = sentimentr_jockers$sentiment,\n","                                'sentimentr_huliu' = sentimentr_huliu$sentiment,\n","                                'sentimentr_nrc' = sentimentr_nrc$sentiment,\n","                                'sentimentr_senticnet' = sentimentr_senticnet$sentiment,\n","                                'sentimentr_sentiword' = sentimentr_sentiword$sentiment,\n","                                'sentimentr_loughran_mcdonald' = sentimentr_loughran_mcdonald$sentiment,\n","                                'sentimentr_socal_google' = sentimentr_socal_google$sentiment\n","                                )\n","  return(anovel_sentimentr_df)\n","\n","}"],"metadata":{"id":"DjytKCXPjZ_o"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["!cat get_sentimentr.R"],"metadata":{"id":"baykTTfbkROx"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Setup python robject with external library::function()\n","# https://rpy2.github.io/doc/v3.0.x/html/generated_rst/pandas.html\n","\n","# import rpy2.robjects as robjects\n","\n","# Defining the R script and loading the instance in Python\n","# from rpy2.robjects import pandas2ri \n","r = robjects.r\n","\n","# Loading the function we have defined in R.\n","r['source']('get_sentimentr.R')\n","\n","# Reading and processing data\n","get_sentimentr_function_r = robjects.globalenv['get_sentimentr_values']"],"metadata":{"id":"zGpOb1CNkRLJ"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Test\n","\n","# Convert Python List of Strings to a R vector of characters\n","test_ls = novels_all_dt['cdickens_achristmascarol']['text_clean'].to_list()\n","s_v = robjects.StrVector(test_ls)\n","type(s_v)\n","\n","get_sentimentr_function_r(s_v)"],"metadata":{"id":"-bYu1QKMmMBR"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["novels_dt.keys()"],"metadata":{"id":"ydWdrTWfxWdE"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["text_clean_ct = novels_all_dt['dbrown_thedavincicode'].text_clean.isna().sum()\n","text_clean_ct\n","# len(text_clean_ls.isnull())"],"metadata":{"id":"mJOt0G-kyhJu"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["**[RE-EXECUTE] May have to re-execute following code cell several times**"],"metadata":{"id":"xi-unkmAJLJl"}},{"cell_type":"code","source":["%%time\n","\n","# NOTE: 8m19s 13 Novels \n","#      16m39s 19 Novels\n","#     -----------------\n","#      24m58s 32 Novels\n","\n","#      10m58s 10 Novels 14:39 at 20220115\n","#             32 Novels\n","\n","# Call external get_sentimentr::get_sentimentr_values with Python loop over all novels\n","\n","# novels_sentimentr_df = {}\n","\n","anovel_df = pd.DataFrame()\n","\n","novels_keys_ls = list(novels_all_dt.keys())\n","novels_keys_ls.sort()\n","# for i, anovel in enumerate(novels_keys_ls[:19]):\n","for i, anovel in enumerate(novels_keys_ls):  \n","  print(f'\\nNovel #{i}: {anovel}')\n","  print(f'     {novels_all_dt[anovel].shape}')\n","  # Get text_clean as list of strings\n","  text_clean_ls = novels_all_dt[anovel]['text_clean'].to_list()\n","\n","  # Convert Python List of Strings to a R vector of characters\n","  # https://rpy2.github.io/doc/v3.0.x/html/generated_rst/pandas.html\n","  s_v = robjects.StrVector(text_clean_ls)\n","  anovel_df_r = get_sentimentr_function_r(s_v)\n","\n","  # Convert rpy2.robjects.vectors.DataFrame to pandas.core.frame.DataFrame\n","  # https://stackoverflow.com/questions/20630121/pandas-how-to-convert-r-dataframe-back-to-pandas \n","  print(f'type(anovel_df_r): {type(anovel_df_r)}')\n","  anovel_df = pd.DataFrame.from_dict({ key : np.asarray(anovel_df_r.rx2(key)) for key in anovel_df_r.names })\n","  print(f'type(anovel_df): {type(anovel_df)}')\n","\n","  # Save Results\n","  novels_sentimentr_dt[anovel] = anovel_df.copy(deep=True)\n"],"metadata":{"id":"s3EW-6zVlGxW"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["type(novels_sentimentr_df)"],"metadata":{"id":"xjtPRa6oD0Iz"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["### Save Checkpoint"],"metadata":{"id":"KmvRotzK2Ot-"}},{"cell_type":"code","source":["# Verify save_to directory\n","\n","subdir_sentiments\n","print('\\n')\n","!ls $subdir_sentiments"],"metadata":{"id":"4VwIdPMH2OuA"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["novels_sentimentr_dt.keys()"],"metadata":{"id":"xnCEB0ElDXnq"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["novels_sentimentr_dt['cdickens_achristmascarol'])"],"metadata":{"id":"KSmUDZZxDPpK"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Save sentiment values to subdir_sentiments\n","\n","write_dict_dfs(novels_sentimentr_dt, out_file='all_7sentimentr.json', out_dir=subdir_sentiments)"],"metadata":{"id":"JOUmHppA2OuC"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["## Plot SentimentR 7 Models"],"metadata":{"id":"8g41AtTk2OuD"}},{"cell_type":"code","source":["#@markdown Select option to save plots:\n","Save_Raw_Plots = True #@param {type:\"boolean\"}\n","\n","Save_Smooth_Plots = True #@param {type:\"boolean\"}\n","Resolution = \"100\" #@param [\"100\", \"300\"]\n","\n"],"metadata":{"id":"crebkDiI2OuE"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["sentimentr_cols_ls = novels_sentimentr_dt['cdickens_achristmascarol'].columns\n","sentimentr_models_ls = [x for x in sentimentr_cols_ls if 'sentimentr_' in x]\n","sentimentr_models_ls\n","\n","# OR\n","\n","# syuzhetr_models_ls = ['syuzhetr_afinn', 'syuzhetr_bing', 'syuzhetr_nrc', 'syuzhetr_syuzhet']"],"metadata":{"id":"hZoBK_2_2OuF"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Verify 4 Sentiment Models from Syuzhet for sample Novel\n","\n","for i, anovel in enumerate(list(novels_all_dt.keys())):\n","\n","  # Raw Sentiments \n","  fig = novels_sentimentr_dt[anovel][sentimentr_models_ls].plot(title=f'{novels_dt[anovel][0]}\\n SentimentR 7 Models: Raw Sentiments', alpha=0.3)\n","  plt.show()\n","\n","  if Save_Raw_Plots:\n","    plt.savefig(f'{subdir_plots_arcs}plot_sentimentr_raw_{anovel}_dpi{Resolution}.png', dpi=int(Resolution))\n","\n","  \n","  # Smoothed Sentiments (SMA 10%)\n","  # novel_sample = 'cdickens_achristmascarol'\n","  win_10per = int(novels_sentimentr_dt[anovel].shape[0] * 0.1)\n","  novels_sentimentr_dt[anovel][sentimentr_models_ls].rolling(win_10per, center=True, min_periods=0).mean().plot(title=f'{novels_dt[anovel][0]}\\n SentimentR 7 Models: Smoothed Sentiments (SMA 10%)', alpha=0.3)\n","  plt.show()\n","\n","  if Save_Smooth_Plots:\n","    plt.savefig(f'{subdir_plots_arcs}plot_sentimentr_smooth10sma_{anovel}_dpi{Resolution}.png', dpi=int(Resolution))\n"],"metadata":{"id":"rWlXnMdR2OuH"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["# **END OF NOTEBOOK**"],"metadata":{"id":"YC3xCnGF22td"}},{"cell_type":"code","source":[""],"metadata":{"id":"gB5vNBhO22lX"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":[""],"metadata":{"id":"2SLgidY322hg"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["### Save Checkpoint"],"metadata":{"id":"Q0snuSEz2g0p"}},{"cell_type":"code","source":["# Verify save_to directory\n","\n","subdir_sentiments\n","print('\\n')\n","!ls $subdir_sentiments"],"metadata":{"id":"-xGo0TaG2g0r"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Save sentiment values to subdir_sentiments\n","\n","write_dict_dfs(novels_syuzhetr_dt, out_file='all_4syuzhetr.json', out_dir=subdir_sentiments)"],"metadata":{"id":"3iGVDnw82g0v"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["## Plot SyuzhetR 4 Models"],"metadata":{"id":"7oQ7dGgo2g0x"}},{"cell_type":"code","source":["#@markdown Select option to save plots:\n","Save_Raw_Plots = True #@param {type:\"boolean\"}\n","\n","Save_Smooth_Plots = True #@param {type:\"boolean\"}\n","Resolution = \"100\" #@param [\"100\", \"300\"]\n","\n"],"metadata":{"id":"b8pQsDh12g0y"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["syuzhetr_cols_ls = novels_syuzhetr_dt['cdickens_achristmascarol'].columns\n","syuzhetr_models_ls = [x for x in syuzhetr_cols_ls if 'syuzhetr_' in x]\n","syuzhetr_models_ls\n","\n","# OR\n","\n","# syuzhetr_models_ls = ['syuzhetr_afinn', 'syuzhetr_bing', 'syuzhetr_nrc', 'syuzhetr_syuzhet']"],"metadata":{"id":"Qa1VfIot2g0z"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["novels_dt['cdickens_achristmascarol'][0]"],"metadata":{"id":"mQDcVi0E2g01"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["subdir_plots_arcs"],"metadata":{"id":"KxAUXaXN2g02"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Verify 4 Sentiment Models from Syuzhet for sample Novel\n","\n","for i, anovel in enumerate(list(novels_all_dt.keys())):\n","\n","  # Raw Sentiments \n","  fig = novels_syuzhetr_dt[anovel][syuzhetr_models_ls].plot(title=f'{novels_dt[anovel][0]}\\n SyuzhetR 4 Models: Raw Sentiments', alpha=0.3)\n","  plt.show()\n","\n","  if Save_Raw_Plots:\n","    plt.savefig(f'{subdir_plots_arcs}plot_syuzhetr_raw_{anovel}_dpi{Resolution}.png', dpi=int(Resolution))\n","\n","  \n","  # Smoothed Sentiments (SMA 10%)\n","  # novel_sample = 'cdickens_achristmascarol'\n","  win_10per = int(novels_syuzhetr_dt[anovel].shape[0] * 0.1)\n","  novels_syuzhetr_dt[anovel][syuzhetr_models_ls].rolling(win_10per, center=True, min_periods=0).mean().plot(title=f'{novels_dt[anovel][0]}\\n SyuzhetR 4 Models: Smoothed Sentiments (SMA 10%)', alpha=0.3)\n","  plt.show()\n","\n","  if Save_Smooth_Plots:\n","    plt.savefig(f'{subdir_plots_arcs}plot_syuzhetr_smooth10sma_{anovel}_dpi{Resolution}.png', dpi=int(Resolution))\n"],"metadata":{"id":"F2mkJt5_2g04"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["### Save Checkpoint"],"metadata":{"id":"OHz2CR3f2hKA"}},{"cell_type":"code","source":["# Verify save_to directory\n","\n","subdir_sentiments\n","print('\\n')\n","!ls $subdir_sentiments"],"metadata":{"id":"xc7iQUvD2hKA"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Save sentiment values to subdir_sentiments\n","\n","write_dict_dfs(novels_syuzhetr_dt, out_file='all_4syuzhetr.json', out_dir=subdir_sentiments)"],"metadata":{"id":"x2de_Aay2hKC"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["## Plot SyuzhetR 4 Models"],"metadata":{"id":"TBS96Uoo2hKC"}},{"cell_type":"code","source":["#@markdown Select option to save plots:\n","Save_Raw_Plots = True #@param {type:\"boolean\"}\n","\n","Save_Smooth_Plots = True #@param {type:\"boolean\"}\n","Resolution = \"100\" #@param [\"100\", \"300\"]\n","\n"],"metadata":{"id":"NLglKZVk2hKD"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["syuzhetr_cols_ls = novels_syuzhetr_dt['cdickens_achristmascarol'].columns\n","syuzhetr_models_ls = [x for x in syuzhetr_cols_ls if 'syuzhetr_' in x]\n","syuzhetr_models_ls\n","\n","# OR\n","\n","# syuzhetr_models_ls = ['syuzhetr_afinn', 'syuzhetr_bing', 'syuzhetr_nrc', 'syuzhetr_syuzhet']"],"metadata":{"id":"kNltQS332hKD"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["novels_dt['cdickens_achristmascarol'][0]"],"metadata":{"id":"jJ533jGq2hKE"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["subdir_plots_arcs"],"metadata":{"id":"cNLzuNBJ2hKF"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Verify 4 Sentiment Models from Syuzhet for sample Novel\n","\n","for i, anovel in enumerate(list(novels_all_dt.keys())):\n","\n","  # Raw Sentiments \n","  fig = novels_syuzhetr_dt[anovel][syuzhetr_models_ls].plot(title=f'{novels_dt[anovel][0]}\\n SyuzhetR 4 Models: Raw Sentiments', alpha=0.3)\n","  plt.show()\n","\n","  if Save_Raw_Plots:\n","    plt.savefig(f'{subdir_plots_arcs}plot_syuzhetr_raw_{anovel}_dpi{Resolution}.png', dpi=int(Resolution))\n","\n","  \n","  # Smoothed Sentiments (SMA 10%)\n","  # novel_sample = 'cdickens_achristmascarol'\n","  win_10per = int(novels_syuzhetr_dt[anovel].shape[0] * 0.1)\n","  novels_syuzhetr_dt[anovel][syuzhetr_models_ls].rolling(win_10per, center=True, min_periods=0).mean().plot(title=f'{novels_dt[anovel][0]}\\n SyuzhetR 4 Models: Smoothed Sentiments (SMA 10%)', alpha=0.3)\n","  plt.show()\n","\n","  if Save_Smooth_Plots:\n","    plt.savefig(f'{subdir_plots_arcs}plot_syuzhetr_smooth10sma_{anovel}_dpi{Resolution}.png', dpi=int(Resolution))\n"],"metadata":{"id":"W9G9190h2hKG"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["### Save Checkpoint"],"metadata":{"id":"0Owz1SiS2hgd"}},{"cell_type":"code","source":["# Verify save_to directory\n","\n","subdir_sentiments\n","print('\\n')\n","!ls $subdir_sentiments"],"metadata":{"id":"tAyujtPX2hge"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Save sentiment values to subdir_sentiments\n","\n","write_dict_dfs(novels_syuzhetr_dt, out_file='all_4syuzhetr.json', out_dir=subdir_sentiments)"],"metadata":{"id":"gfGY5mqE2hgf"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["## Plot SyuzhetR 4 Models"],"metadata":{"id":"7tnEQFmA2hgh"}},{"cell_type":"code","source":["#@markdown Select option to save plots:\n","Save_Raw_Plots = True #@param {type:\"boolean\"}\n","\n","Save_Smooth_Plots = True #@param {type:\"boolean\"}\n","Resolution = \"100\" #@param [\"100\", \"300\"]\n","\n"],"metadata":{"id":"4GQC86Hg2hgh"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["syuzhetr_cols_ls = novels_syuzhetr_dt['cdickens_achristmascarol'].columns\n","syuzhetr_models_ls = [x for x in syuzhetr_cols_ls if 'syuzhetr_' in x]\n","syuzhetr_models_ls\n","\n","# OR\n","\n","# syuzhetr_models_ls = ['syuzhetr_afinn', 'syuzhetr_bing', 'syuzhetr_nrc', 'syuzhetr_syuzhet']"],"metadata":{"id":"z1XHrniJ2hgi"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["novels_dt['cdickens_achristmascarol'][0]"],"metadata":{"id":"QS9zW4aw2hgj"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["subdir_plots_arcs"],"metadata":{"id":"e-xMUCvK2hgk"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Verify 4 Sentiment Models from Syuzhet for sample Novel\n","\n","for i, anovel in enumerate(list(novels_all_dt.keys())):\n","\n","  # Raw Sentiments \n","  fig = novels_syuzhetr_dt[anovel][syuzhetr_models_ls].plot(title=f'{novels_dt[anovel][0]}\\n SyuzhetR 4 Models: Raw Sentiments', alpha=0.3)\n","  plt.show()\n","\n","  if Save_Raw_Plots:\n","    plt.savefig(f'{subdir_plots_arcs}plot_syuzhetr_raw_{anovel}_dpi{Resolution}.png', dpi=int(Resolution))\n","\n","  \n","  # Smoothed Sentiments (SMA 10%)\n","  # novel_sample = 'cdickens_achristmascarol'\n","  win_10per = int(novels_syuzhetr_dt[anovel].shape[0] * 0.1)\n","  novels_syuzhetr_dt[anovel][syuzhetr_models_ls].rolling(win_10per, center=True, min_periods=0).mean().plot(title=f'{novels_dt[anovel][0]}\\n SyuzhetR 4 Models: Smoothed Sentiments (SMA 10%)', alpha=0.3)\n","  plt.show()\n","\n","  if Save_Smooth_Plots:\n","    plt.savefig(f'{subdir_plots_arcs}plot_syuzhetr_smooth10sma_{anovel}_dpi{Resolution}.png', dpi=int(Resolution))\n"],"metadata":{"id":"Qg_rXA6d2hgk"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":[""],"metadata":{"id":"zitFX3frkUpO"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":[""],"metadata":{"id":"Y3gdoeXakUmF"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["%%R -i s_v -i novels_roots -o novels_sentimentr_df\n","\n","# novels_key_ls = c('cdickens_achristmascarol')\n","\n","get_sentimentr_vals = function()\n","print('Processing sentimentr_jockersrinker')\n","sentimentr_jockersrinker <- sentiment(s_v, polarity_dt=lexicon::hash_sentiment_jockers_rinker, \n","                                      hypen=\"\", amplifier.weight=0.8, n.before=5, n.after=2,\n","                                      adversative.weight=0.25, neutral.nonverb.like = FALSE, missing_value = 0)\n","\n","print('Processing sentimentr_jockers')\n","sentimentr_jockers <- sentiment(s_v, polarity_dt=lexicon::hash_sentiment_jockers, \n","                                      hypen=\"\", amplifier.weight=0.8, n.before=5, n.after=2,\n","                                      adversative.weight=0.25, neutral.nonverb.like = FALSE, missing_value = 0)\n","\n","print('Processing sentimentr_huliu')\n","sentimentr_huliu <- sentiment(s_v, polarity_dt=lexicon::hash_sentiment_huliu, \n","                                      hypen=\"\", amplifier.weight=0.8, n.before=5, n.after=2,\n","                                      adversative.weight=0.25, neutral.nonverb.like = FALSE, missing_value = 0)\n","\n","print('Processing sentimentr_nrc')\n","sentimentr_nrc <- sentiment(s_v, polarity_dt=lexicon::hash_sentiment_nrc, \n","                                      hypen=\"\", amplifier.weight=0.8, n.before=5, n.after=2,\n","                                      adversative.weight=0.25, neutral.nonverb.like = FALSE, missing_value = 0)\n","\n","print('Processing sentimentr_senticnet')\n","sentimentr_senticnet <- sentiment(s_v, polarity_dt=lexicon::hash_sentiment_senticnet, \n","                                      hypen=\"\", amplifier.weight=0.8, n.before=5, n.after=2,\n","                                      adversative.weight=0.25, neutral.nonverb.like = FALSE, missing_value = 0)\n","\n","print('Processing sentimentr_sentiword')\n","sentimentr_sentiword <- sentiment(s_v, polarity_dt=lexicon::hash_sentiment_sentiword, \n","                                      hypen=\"\", amplifier.weight=0.8, n.before=5, n.after=2,\n","                                      adversative.weight=0.25, neutral.nonverb.like = FALSE, missing_value = 0)\n","\n","print('Processing sentimentr_loughran_mcdonald')\n","sentimentr_loughran_mcdonald <- sentiment(s_v, polarity_dt=lexicon::hash_sentiment_loughran_mcdonald, \n","                                      hypen=\"\", amplifier.weight=0.8, n.before=5, n.after=2,\n","                                      adversative.weight=0.25, neutral.nonverb.like = FALSE, missing_value = 0)\n","\n","print('Processing sentimentr_socal_google')\n","sentimentr_socal_google <- sentiment(s_v, polarity_dt=lexicon::hash_sentiment_socal_google, \n","                                      hypen=\"\", amplifier.weight=0.8, n.before=5, n.after=2,\n","                                      adversative.weight=0.25, neutral.nonverb.like = FALSE, missing_value = 0)\n","\n","novels_sentimentr_df <- data.frame('text_clean' = s_v,\n","                              'sentimentr_jockersrinker' = sentimentr_jockersrinker$sentiment,\n","                              'sentimentr_jockers' = sentimentr_jockers$sentiment,\n","                              'sentimentr_huliu' = sentimentr_huliu$sentiment,\n","                              'sentimentr_nrc' = sentimentr_nrc$sentiment,\n","                              'sentimentr_senticnet' = sentimentr_senticnet$sentiment,\n","                              'sentimentr_sentiword' = sentimentr_sentiword$sentiment,\n","                              'sentimentr_loughran_mcdonald' = sentimentr_loughran_mcdonald$sentiment,\n","                              'sentimentr_socal_google' = sentimentr_socal_google$sentiment\n","                              )\n"],"metadata":{"id":"js6-95fUi-Rj"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["%%R -i s_v -i novels_roots -o novels_sentimentr_df\n","\n","# novels_key_ls = c('cdickens_achristmascarol')\n","\n","\n","print('Processing sentimentr_jockersrinker')\n","sentimentr_jockersrinker <- sentiment(s_v, polarity_dt=lexicon::hash_sentiment_jockers_rinker, \n","                                      hypen=\"\", amplifier.weight=0.8, n.before=5, n.after=2,\n","                                      adversative.weight=0.25, neutral.nonverb.like = FALSE, missing_value = 0)\n","\n","print('Processing sentimentr_jockers')\n","sentimentr_jockers <- sentiment(s_v, polarity_dt=lexicon::hash_sentiment_jockers, \n","                                      hypen=\"\", amplifier.weight=0.8, n.before=5, n.after=2,\n","                                      adversative.weight=0.25, neutral.nonverb.like = FALSE, missing_value = 0)\n","\n","print('Processing sentimentr_huliu')\n","sentimentr_huliu <- sentiment(s_v, polarity_dt=lexicon::hash_sentiment_huliu, \n","                                      hypen=\"\", amplifier.weight=0.8, n.before=5, n.after=2,\n","                                      adversative.weight=0.25, neutral.nonverb.like = FALSE, missing_value = 0)\n","\n","print('Processing sentimentr_nrc')\n","sentimentr_nrc <- sentiment(s_v, polarity_dt=lexicon::hash_sentiment_nrc, \n","                                      hypen=\"\", amplifier.weight=0.8, n.before=5, n.after=2,\n","                                      adversative.weight=0.25, neutral.nonverb.like = FALSE, missing_value = 0)\n","\n","print('Processing sentimentr_senticnet')\n","sentimentr_senticnet <- sentiment(s_v, polarity_dt=lexicon::hash_sentiment_senticnet, \n","                                      hypen=\"\", amplifier.weight=0.8, n.before=5, n.after=2,\n","                                      adversative.weight=0.25, neutral.nonverb.like = FALSE, missing_value = 0)\n","\n","print('Processing sentimentr_sentiword')\n","sentimentr_sentiword <- sentiment(s_v, polarity_dt=lexicon::hash_sentiment_sentiword, \n","                                      hypen=\"\", amplifier.weight=0.8, n.before=5, n.after=2,\n","                                      adversative.weight=0.25, neutral.nonverb.like = FALSE, missing_value = 0)\n","\n","print('Processing sentimentr_loughran_mcdonald')\n","sentimentr_loughran_mcdonald <- sentiment(s_v, polarity_dt=lexicon::hash_sentiment_loughran_mcdonald, \n","                                      hypen=\"\", amplifier.weight=0.8, n.before=5, n.after=2,\n","                                      adversative.weight=0.25, neutral.nonverb.like = FALSE, missing_value = 0)\n","\n","print('Processing sentimentr_socal_google')\n","sentimentr_socal_google <- sentiment(s_v, polarity_dt=lexicon::hash_sentiment_socal_google, \n","                                      hypen=\"\", amplifier.weight=0.8, n.before=5, n.after=2,\n","                                      adversative.weight=0.25, neutral.nonverb.like = FALSE, missing_value = 0)\n","\n","novels_sentimentr_df <- data.frame('text_clean' = s_v,\n","                              'sentimentr_jockersrinker' = sentimentr_jockersrinker$sentiment,\n","                              'sentimentr_jockers' = sentimentr_jockers$sentiment,\n","                              'sentimentr_huliu' = sentimentr_huliu$sentiment,\n","                              'sentimentr_nrc' = sentimentr_nrc$sentiment,\n","                              'sentimentr_senticnet' = sentimentr_senticnet$sentiment,\n","                              'sentimentr_sentiword' = sentimentr_sentiword$sentiment,\n","                              'sentimentr_loughran_mcdonald' = sentimentr_loughran_mcdonald$sentiment,\n","                              'sentimentr_socal_google' = sentimentr_socal_google$sentiment\n","                              )\n"],"metadata":{"id":"x2tUu2-LT0Sh"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["novels_sentimentr_df.head()"],"metadata":{"id":"42SRo0j_YLzU"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Get list of sentimentr models from columns\n","\n","sentimentr_models_ls = [x for x in novels_sentimentr_df.columns if 'sentimentr_' in x]\n","sentimentr_models_ls"],"metadata":{"id":"T-rvzX6efDXu"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Verify 4 Sentiment Models from Syuzhet for sample Novel\n","\n","# Raw Sentiments \n","# novels_all_dt['cdickens_achristmascarol'][['syuzhetr_syuzhet','syuzhetr_bing','syuzhetr_afinn','syuzhetr_nrc']].plot(title='Raw Sentiments', alpha=0.3)\n","novels_sentimentr_df[sentimentr_models_ls].plot(title='SentimentR Raw Sentiments', alpha=0.3)\n","\n","# Smoothed Sentiments (SMA 10%)\n","novel_sample = 'cdickens_achristmascarol'\n","win_10per = int(novels_all_dt['cdickens_achristmascarol'].shape[0] * 0.1)\n","novels_sentimentr_df[sentimentr_models_ls].rolling(win_10per, center=True, min_periods=0).mean().plot(title='SentimentR Smoothed Sentiments (SMA 10%)', alpha=0.3)\n","plt.show()\n"],"metadata":{"id":"4ZxQLF6te9B3"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":[""],"metadata":{"id":"NLMk4NRxe8-M"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":[""],"metadata":{"id":"rINIR_Ase86-"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":[""],"metadata":{"id":"rmAHKE5ze84V"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":[""],"metadata":{"id":"g4YJifvve8zE"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["%%file get_sentimentr.R\n","\n","library(sentimentr)\n","library(lexicon)\n","\n","get_sentimentr_values <- function(df_name, col_name){\n","  #' Preprocessing df to filter country\n","  #'\n","  #' This function returns a subset of the df\n","  #' if the value of the country column contains \n","  #' the country we are passing\n","  #'\n","  #' @param df The dataframe containing the data \n","  #' @param country The country we want to filter\n","  #\n","  print('Processing sentimentr_jockers')\n","  sentimentr_jockers <- sentiment(df_name$col_name, polarity_dt=lexicon::hash_sentiment_jockers, \n","                                      hypen=\"\", amplifier.weight=0.8, n.before=5, n.after=2,\n","                                      adversative.weight=0.25, neutral.nonverb.like = FALSE, missing_value = 0)\n","\n","\n","\n","  return(sentimentr_jockers)\n","}"],"metadata":{"id":"gxfD5M9qYLwc"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["!cat get_sentimentr.R"],"metadata":{"id":"DNTH7egtZz4x"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["df = novels_all_dt['cdickens_achristmascarol']\n","df.head()"],"metadata":{"id":"CbcpMh0japlC"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["dir(pandas2ri)"],"metadata":{"id":"8CUNRe87a8Nw"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# https://medium.com/analytics-vidhya/calling-r-from-python-magic-of-rpy2-d8cbbf991571\n","\n","# import rpy2.robjects as robjects\n","from rpy2.robjects import pandas2ri# Defining the R script and loading the instance in Python\n","from rpy2.robjects.conversion import localconverter\n","\n","r = robjects.r\n","r['source']('get_sentimentr.R')# Loading the function we have defined in R.\n","sentimentr_function_r = robjects.globalenv['get_sentimentr_values']\n","\n","# r['source']('sentimentr')# Loading the function we have defined in R.\n","# sentiment_function_r = robjects.globalenv['sentiment']\n","\n","# Reading and processing data\n","# df = pd.read_csv(\"Country-Sales.csv\")#converting it into r object for passing into r function\n","df = novels_all_dt['cdickens_achristmascarol']\n","with localconverter(robjects.default_converter + pandas2ri.converter):\n","  df_r = robjects.conversion.py2rpy(df)\n","\n","# df_r = pandas2ri.py2rpy_dataframe(df)\n","\n","#Invoking the R function and getting the result\n","df_result_r = sentimentr_function_r(df_r, 'text_clean')\n","\n","#Converting it back to a pandas dataframe.\n","df_result = pandas2ri.py2ri(df_result_r)\n","\n","df_result.head()\n","\n"],"metadata":{"id":"DiN-2Ue2YLtr"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["## Save Checkpoint\n"],"metadata":{"id":"Yc95E8mp1Sqj"}},{"cell_type":"code","source":[""],"metadata":{"id":"xte2Mb8409EL"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["# **END OF NOTEBOOK**"],"metadata":{"id":"j_-Xbjgw1UXm"}},{"cell_type":"code","source":["pd.DataFrame(syuzhetr_syuzhet).plot()"],"metadata":{"id":"pcuNlzrJyaza"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":[""],"metadata":{"id":"Y5XxwepyvVqb"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":[""],"metadata":{"id":"p7Of4C6gvVno"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["install.packages('syuzhet')\n","library(syuzhet)"],"metadata":{"id":"dksRvTEKjC-j"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["files <- list.files(pattern=\"*.csv\", full.names=TRUE, recursive=FALSE)\n","length(files)"],"metadata":{"id":"rCqvE9P1hqv-"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["files[1]"],"metadata":{"id":"ldeNsLd9hs0G"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["sentiment_syuzhet <- get_sentiment(s_v, method='syuzhet')\n","sentiment_syuzhet"],"metadata":{"id":"tmYKz-_WiR2I"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["get_syuzhetr_sentiments <- function(afilename) {\n","  anovel_df <- read.csv(file = afilename, header=FALSE)\n","  # typeof(anovel_df$V3)\n","  # return(anovel_df)\n","  s_v <- anovel_df$V3\n","\n","  syuzhetr_jockers <- get_sentiment(s_v, method='syuzhet')\n","  syuzhetr_bing <- get_sentiment(s_v, method='bing')\n","  syuzhetr_afinn <- get_sentiment(s_v, method='afinn')\n","  syuzhetr_nrc <- get_sentiment(s_v, method='nrc')\n","\n","  syuzhet_df <- data.frame(syuzhetr_jockers,\n","                           syuzhetr_bing,\n","                           syuzhetr_afinn,\n","                           syuzhetr_nrc)\n","\n","  return(syuzhet_df)\n","}"],"metadata":{"id":"N8olYxZ8bada"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["get_syuzhetr_sentiments(files[1])"],"metadata":{"id":"nyZogtQmheZ2"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["get_syuzhetr_sentiments()"],"metadata":{"id":"XT8jdA8ghcp3"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["lapply(files, function(x) {\n","  print(paste0('Novel: ', x))\n","  anovel_df <- read.csv(file = x, header=FALSE)\n","  syuzhetr_df <- get_syuzhetr_sentiments(anovel_df)\n","  head(anovel_df)\n","})"],"metadata":{"id":"VUVXbBqAhRAt"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["## Syuzhet Lexicon"],"metadata":{"id":"h3-D3sVCHzT8"}},{"cell_type":"code","source":["sentiment_syuzhet <- get_sentiment(s_v, method='syuzhet')\n","sentiment_syuzhet"],"metadata":{"id":"vbWIn0uD5u8B"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["simple_plot(sentiment_syuzhet)"],"metadata":{"id":"cZR21h6Y5u5S"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["s_v_sentiment_dct <- get_dct_transform(\n","  sentiment_syuzhet,\n","  low_pass_size = 5,\n","  x_reverse_len = 100,\n","  scale_vals = F,\n","  scale_range = T\n",")\n","plot(\n","  s_v_sentiment_dct,\n","  type = 'l',\n","  main=\"DCT Transformed Syuzhet Sentiments\",\n","  xlab = \"Narrative Time\",\n","  ylab = \"Emotional Valence\",\n","  col = \"red\"\n",")"],"metadata":{"id":"8ZgJCNNe5u2F"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["## Bing Lexicon"],"metadata":{"id":"WOjdx3txEEF8"}},{"cell_type":"code","source":["sentiment_bing <- get_sentiment(s_v, method='bing')\n","sentiment_bing"],"metadata":{"id":"geE-mUSIEK2u"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["simple_plot(sentiment_bing)"],"metadata":{"id":"mCy57Cq4EK2w"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["s_v_sentiment_dct <- get_dct_transform(\n","  sentiment_bing,\n","  low_pass_size = 5,\n","  x_reverse_len = 100,\n","  scale_vals = F,\n","  scale_range = T\n",")\n","plot(\n","  s_v_sentiment_dct,\n","  type = 'l',\n","  main=\"DCT Transformed Bing Sentiments\",\n","  xlab = \"Narrative Time\",\n","  ylab = \"Emotional Valence\",\n","  col = \"red\"\n",")"],"metadata":{"id":"cE0qf6TQEK2w"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["## AFINN Lexicon"],"metadata":{"id":"iU_F2OzQEru6"}},{"cell_type":"code","source":["sentiment_afinn <- get_sentiment(s_v, method='afinn')\n","sentiment_afinn"],"metadata":{"id":"fSuCdTmwExkY"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["simple_plot(sentiment_afinn)"],"metadata":{"id":"YRSUZDGfExka"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["s_v_sentiment_dct <- get_dct_transform(\n","  sentiment_afinn,\n","  low_pass_size = 5,\n","  x_reverse_len = 100,\n","  scale_vals = F,\n","  scale_range = T\n",")\n","plot(\n","  s_v_sentiment_dct,\n","  type = 'l',\n","  main=\"DCT Transformed AFINN Sentiments\",\n","  xlab = \"Narrative Time\",\n","  ylab = \"Emotional Valence\",\n","  col = \"red\"\n",")"],"metadata":{"id":"I7EIYVGOExkc"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["## NRC Lexicon"],"metadata":{"id":"MLsS_hMBEt6H"}},{"cell_type":"code","source":["sentiment_nrc <- get_sentiment(s_v, method='nrc')\n","sentiment_nrc"],"metadata":{"id":"o4oy1fAQEyKL"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["simple_plot(sentiment_nrc)"],"metadata":{"id":"_Br13AJDEyKN"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["s_v_sentiment_dct <- get_dct_transform(\n","  sentiment_nrc,\n","  low_pass_size = 5,\n","  x_reverse_len = 100,\n","  scale_vals = F,\n","  scale_range = T\n",")\n","plot(\n","  s_v_sentiment_dct,\n","  type = 'l',\n","  main=\"DCT Transformed Bing Sentiments\",\n","  xlab = \"Narrative Time\",\n","  ylab = \"Emotional Valence\",\n","  col = \"red\"\n",")"],"metadata":{"id":"AeEDvHSCEyKO"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["## Stanford Lexicon (Disabled, req Java OpenNLP)"],"metadata":{"id":"5ctQ2sy4FVna"}},{"cell_type":"code","source":["sentiment_stanford <- get_sentiment(s_v, method='stanford')\n","sentiment_stanford"],"metadata":{"id":"v1DLKk-nFZaJ"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["simple_plot(sentiment_nrc)"],"metadata":{"id":"BYNH4rkWFZaL"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["s_v_sentiment_dct <- get_dct_transform(\n","  sentiment_nrc,\n","  low_pass_size = 5,\n","  x_reverse_len = 100,\n","  scale_vals = F,\n","  scale_range = T\n",")\n","plot(\n","  s_v_sentiment_dct,\n","  type = 'l',\n","  main=\"DCT Transformed Bing Sentiments\",\n","  xlab = \"Narrative Time\",\n","  ylab = \"Emotional Valence\",\n","  col = \"red\"\n",")"],"metadata":{"id":"MrA4D8ITFZaM"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["## Combine all SyuzhetR Lexicons"],"metadata":{"id":"jZbxIv2DRoQz"}},{"cell_type":"code","source":["syuzhetr_all_df <- data.frame(syuzhet = sentiment_syuzhet,\n","                              bing = sentiment_bing,\n","                              afinn = sentiment_afinn,\n","                              nrc = sentiment_nrc)\n","\n","syuzhetr_all_df"],"metadata":{"id":"kWc5EHcxRoQ0"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["write.csv(syuzhetr_all_df, 'syuzhetr_novel.csv', row.names=FALSE)"],"metadata":{"id":"xK-BqMnIRoQ2"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["# SentimentR Library\n","\n","* https://github.com/trinker/sentimentr\n","\n","* https://cran.r-project.org/web/packages/sentimentr/"],"metadata":{"id":"PynvhOzlFfVs"}},{"cell_type":"code","source":["install.packages('sentimentr')\n","library(sentimentr)"],"metadata":{"id":"-rUdFu0WErfe"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["if (!require(\"pacman\")) install.packages(\"pacman\")\n","pacman::p_load_gh(\"trinker/sentimentr\", \"trinker/stansent\", \"sfeuerriegel/SentimentAnalysis\", \"wrathematics/meanr\")\n","pacman::p_load(syuzhet, qdap, microbenchmark, RSentiment)"],"metadata":{"id":"OPOsBKR3FpsP"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["files <- list.files(pattern=\"*.csv\", full.names=TRUE, recursive=FALSE)\n","length(files)"],"metadata":{"id":"LftQQ3EjkRQt"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["files[1]"],"metadata":{"id":"DIKSfT8JkRQu"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["sentiment_syuzhet <- get_sentiment(s_v, method='syuzhet')\n","sentiment_syuzhet"],"metadata":{"id":"NMZsAzxwkRQv"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["get_sentimentr_sentiments <- function(afilename) {\n","  anovel_df <- read.csv(file = afilename, header=FALSE)\n","  # typeof(anovel_df$V3)\n","  # return(anovel_df)\n","  s_v <- anovel_df$V3\n","\n","  jockersrinker <- sentiment(s_v, polarity_dt=lexicon::hash_sentiment_jockers_rinker, \n","                                      hypen=\"\", amplifier.weight=0.8, n.before=5, n.after=2,\n","                                      adversative.weight=0.25, neutral.nonverb.like = FALSE, missing_value = 0)\n","\n","  jockers <- sentiment(s_v, polarity_dt=lexicon::hash_sentiment_jockers, \n","                                      hypen=\"\", amplifier.weight=0.8, n.before=5, n.after=2,\n","                                      adversative.weight=0.25, neutral.nonverb.like = FALSE, missing_value = 0)\n","\n","  huliu <- sentiment(s_v, polarity_dt=lexicon::hash_sentiment_huliu, \n","                                      hypen=\"\", amplifier.weight=0.8, n.before=5, n.after=2,\n","                                      adversative.weight=0.25, neutral.nonverb.like = FALSE, missing_value = 0)\n","\n","  loughran_mcdonald <- sentiment(s_v, polarity_dt=lexicon::hash_sentiment_loughran_mcdonald, \n","                                      hypen=\"\", amplifier.weight=0.8, n.before=5, n.after=2,\n","                                      adversative.weight=0.25, neutral.nonverb.like = FALSE, missing_value = 0)\n","\n","  sentimentr_nrc <- sentiment(s_v, polarity_dt=lexicon::hash_sentiment_nrc, \n","                                      hypen=\"\", amplifier.weight=0.8, n.before=5, n.after=2,\n","                                      adversative.weight=0.25, neutral.nonverb.like = FALSE, missing_value = 0)\n","\n","  senticnet <- sentiment(s_v, polarity_dt=lexicon::hash_sentiment_senticnet, \n","                                      hypen=\"\", amplifier.weight=0.8, n.before=5, n.after=2,\n","                                      adversative.weight=0.25, neutral.nonverb.like = FALSE, missing_value = 0)\n","\n","  sentiword <- sentiment(s_v, polarity_dt=lexicon::hash_sentiment_sentiword, \n","                                      hypen=\"\", amplifier.weight=0.8, n.before=5, n.after=2,\n","                                      adversative.weight=0.25, neutral.nonverb.like = FALSE, missing_value = 0)                                                                                                 \n","\n","  socal_google <- sentiment(s_v, polarity_dt=lexicon::hash_sentiment_socal_google, \n","                                      hypen=\"\", amplifier.weight=0.8, n.before=5, n.after=2,\n","                                      adversative.weight=0.25, neutral.nonverb.like = FALSE, missing_value = 0)                                                                                                 \n","\n","  slangsd <- sentiment(s_v, polarity_dt=lexicon::hash_sentiment_slangsd, \n","                                      hypen=\"\", amplifier.weight=0.8, n.before=5, n.after=2,\n","                                      adversative.weight=0.25, neutral.nonverb.like = FALSE, missing_value = 0)                                                                                                 \n","\n","  emojis <- sentiment(s_v, polarity_dt=lexicon::hash_sentiment_emojis, \n","                                      hypen=\"\", amplifier.weight=0.8, n.before=5, n.after=2,\n","                                      adversative.weight=0.25, neutral.nonverb.like = FALSE, missing_value = 0)                                                                                                 \n","\n","  sentimentr_df <- data.frame(element_id = jockersrinker$element_id,\n","                              sentence_id = jockersrinker$sentence_id,\n","                              word_count = jockersrinker$word_count,\n","                              jockers_rinker = jockersrinker$sentiment,\n","                              jockers = jockers$sentiment,\n","                              huliu = huliu$sentiment,\n","                              lmcd = loughran_mcdonald$sentiment,\n","                              nrc = sentimentr_nrc$sentiment,\n","                              senticnet = senticnet$sentiment,\n","                              sentiword = sentiword$sentiment,\n","                              socal_google = socal_google$sentiment,\n","                              slangsd = slangsd$sentiment,\n","                              emojis = emojis$sentiment)\n","  \n","  return(sentimentr_df)\n","}"],"metadata":{"id":"ESDynKSYkRQv"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["files[1]"],"metadata":{"id":"BL-fYNKvrOxr"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["get_sentimentr_sentiments(files[1])"],"metadata":{"id":"RrHOX3hrkRQw"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["typeof(s_v)"],"metadata":{"id":"J5qJBwy8G0bf"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["ase <- c(\n","    \"I haven't been sad in a long time.\",\n","    \"I am extremely happy today.\",\n","    \"It's a good day.\",\n","    \"But suddenly I'm only a little bit happy.\",\n","    \"Then I'm not happy at all.\",\n","    \"In fact, I am now the least happy person on the planet.\",\n","    \"There is no happiness left in me.\",\n","    \"Wait, it's returned!\",\n","    \"I don't feel so bad after all!\"\n",")\n","typeof(ase)"],"metadata":{"id":"_Z6468ahG11s"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["syuzhet <- setNames(as.data.frame(lapply(c(\"syuzhet\", \"bing\", \"afinn\", \"nrc\"),\n","    function(x) get_sentiment(s_v, method=x))), c(\"jockers\", \"bing\", \"afinn\", \"nrc\"))\n"],"metadata":{"id":"aXm9RIi5HmWQ"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["dim(syuzhet)"],"metadata":{"id":"TpMjqG3gJA1u"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["syuzhet"],"metadata":{"id":"2so0Iv1rJRcY"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["## Jockers_Rinker Lexicon"],"metadata":{"id":"3EgYreb_LAPY"}},{"cell_type":"code","source":["SentimentAnalysis <- apply(analyzeSentiment(s_v)[c('SentimentGI', 'SentimentLM', 'SentimentQDAP') ], 2, round, 2)\n","colnames(SentimentAnalysis) <- gsub('^Sentiment', \"SA_\", colnames(SentimentAnalysis))"],"metadata":{"id":"2TtvzccJHmMa"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["sentimentr_jockersrinker <- sentiment(s_v, polarity_dt=lexicon::hash_sentiment_jockers_rinker, \n","                                      hypen=\"\", amplifier.weight=0.8, n.before=5, n.after=2,\n","                                      adversative.weight=0.25, neutral.nonverb.like = FALSE, missing_value = 0)"],"metadata":{"id":"A5A0YLLvJ9B4"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["sentimentr_jockersrinker"],"metadata":{"id":"iLdyr85lJ894"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["## Jockers Lexicon"],"metadata":{"id":"XDx1oAAwLK3S"}},{"cell_type":"code","source":["sentimentr_jockers <- sentiment(s_v, polarity_dt=lexicon::hash_sentiment_jockers, \n","                                      hypen=\"\", amplifier.weight=0.8, n.before=5, n.after=2,\n","                                      adversative.weight=0.25, neutral.nonverb.like = FALSE, missing_value = 0)"],"metadata":{"id":"gVrTkduKLPNT"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["sentimentr_jockers"],"metadata":{"id":"8IRGWU4fLPNV"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["## Hu_Liu Lexicon"],"metadata":{"id":"GFUiD_xlLceP"}},{"cell_type":"code","source":["sentimentr_huliu <- sentiment(s_v, polarity_dt=lexicon::hash_sentiment_huliu, \n","                                      hypen=\"\", amplifier.weight=0.8, n.before=5, n.after=2,\n","                                      adversative.weight=0.25, neutral.nonverb.like = FALSE, missing_value = 0)"],"metadata":{"id":"TGnS5i8ULY_v"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["sentimentr_huliu"],"metadata":{"id":"K1FO9JLiLY_w"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["## Loughran_McDonald Lexicon"],"metadata":{"id":"TEH4yG6jLraJ"}},{"cell_type":"code","source":["sentimentr_loughranmcdonald <- sentiment(s_v, polarity_dt=lexicon::hash_sentiment_loughran_mcdonald, \n","                                      hypen=\"\", amplifier.weight=0.8, n.before=5, n.after=2,\n","                                      adversative.weight=0.25, neutral.nonverb.like = FALSE, missing_value = 0)"],"metadata":{"id":"Cx_KKdP0Lp0f"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["sentimentr_loughranmcdonald"],"metadata":{"id":"a4X77UacLp0g"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["## NRC Lexicon"],"metadata":{"id":"xK1EN9AbL5Qz"}},{"cell_type":"code","source":["sentimentr_nrc <- sentiment(s_v, polarity_dt=lexicon::hash_sentiment_nrc, \n","                                      hypen=\"\", amplifier.weight=0.8, n.before=5, n.after=2,\n","                                      adversative.weight=0.25, neutral.nonverb.like = FALSE, missing_value = 0)"],"metadata":{"id":"pYgsx-PfL_kI"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["sentimentr_nrc"],"metadata":{"id":"dYz_-FxbL_kK"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["## SenticNet Lexicon"],"metadata":{"id":"hjYIdqIVMIcC"}},{"cell_type":"code","source":["sentimentr_senticnet <- sentiment(s_v, polarity_dt=lexicon::hash_sentiment_senticnet, \n","                                      hypen=\"\", amplifier.weight=0.8, n.before=5, n.after=2,\n","                                      adversative.weight=0.25, neutral.nonverb.like = FALSE, missing_value = 0)"],"metadata":{"id":"vxc2OTkpMKfI"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["sentimentr_senticnet"],"metadata":{"id":"CuA6PCshMKfL"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["## SentiWord Lexicon"],"metadata":{"id":"JArDkwzAMXRx"}},{"cell_type":"code","source":["sentimentr_sentiword <- sentiment(s_v, polarity_dt=lexicon::hash_sentiment_sentiword, \n","                                      hypen=\"\", amplifier.weight=0.8, n.before=5, n.after=2,\n","                                      adversative.weight=0.25, neutral.nonverb.like = FALSE, missing_value = 0)"],"metadata":{"id":"jQFhJxWwMSTO"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["sentimentr_sentiword"],"metadata":{"id":"OuJWudlfMSTR"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["## Socal_Google Lexicon"],"metadata":{"id":"7RZsldEHMZoR"}},{"cell_type":"code","source":["sentimentr_socalgoogle <- sentiment(s_v, polarity_dt=lexicon::hash_sentiment_socal_google, \n","                                      hypen=\"\", amplifier.weight=0.8, n.before=5, n.after=2,\n","                                      adversative.weight=0.25, neutral.nonverb.like = FALSE, missing_value = 0)"],"metadata":{"id":"qBkWlsC8Mhlx"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["sentimentr_socalgoogle"],"metadata":{"id":"JJ3lg3jdMhlz"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["## SlangSD Lexicon"],"metadata":{"id":"zNJShUYfM1R2"}},{"cell_type":"code","source":["sentimentr_slangsd <- sentiment(s_v, polarity_dt=lexicon::hash_sentiment_slangsd, \n","                                      hypen=\"\", amplifier.weight=0.8, n.before=5, n.after=2,\n","                                      adversative.weight=0.25, neutral.nonverb.like = FALSE, missing_value = 0)"],"metadata":{"id":"B0tmWRHgMwxV"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["sentimentr_slangsd"],"metadata":{"id":"ZxwmwRJsMwxY"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["## Emoji Lexicon"],"metadata":{"id":"CSZDsDcXPB37"}},{"cell_type":"code","source":["sentimentr_emojis <- sentiment(s_v, polarity_dt=lexicon::hash_sentiment_emojis, \n","                                      hypen=\"\", amplifier.weight=0.8, n.before=5, n.after=2,\n","                                      adversative.weight=0.25, neutral.nonverb.like = FALSE, missing_value = 0)"],"metadata":{"id":"kN066OsTPGec"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["sentimentr_emojis"],"metadata":{"id":"vTkaEA7DPGee"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["## Combine all SentimentR Lexicons"],"metadata":{"id":"qTmkvX80O-un"}},{"cell_type":"code","source":["sentimentr_all_df <- data.frame(element_id = sentimentr_jockersrinker$element_id,\n","                               sentence_id = sentimentr_jockersrinker$sentence_id,\n","                               word_count = sentimentr_jockersrinker$word_count,\n","                               jockersrinker = sentimentr_jockersrinker$sentiment,\n","                               jockers = sentimentr_jockers$sentiment,\n","                               huliu = sentimentr_huliu$sentiment,\n","                               nrc = sentimentr_nrc$sentiment,\n","                               senticnet = sentimentr_senticnet$sentiment,\n","                               sentiword = sentimentr_sentiword$sentiment,\n","                               loughranmcdonald = sentimentr_loughranmcdonald$sentiment,\n","                               socalgoogle = sentimentr_socalgoogle$sentiment,\n","                               slangsd = sentimentr_slangsd$sentiment,\n","                               emojis = sentimentr_emojis$sentiment)\n","\n","sentimentr_all_df"],"metadata":{"id":"DoFQct5kOHTd"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["write.csv(sentimentr_all_df, 'sentiment_novel.csv', row.names=FALSE)"],"metadata":{"id":"rICiRdUDQuK_"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["# Combine SentimentR and SyuzhetR"],"metadata":{"id":"dOdHhaGhSkkh"}},{"cell_type":"code","source":["sentiments_all_df <- merge(syuzhetr_all_df, sentimentr_all_df)\n","sentiments_all_df"],"metadata":{"id":"tbEJkSZLSqW4"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["write.csv(sentiments_all_df, 'sentiments_novel.csv', row.names=FALSE)"],"metadata":{"id":"uBZRvcdkSqKO"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["# Iterate over all files in the Directory"],"metadata":{"id":"-KvAv64Cc3AS"}},{"cell_type":"code","source":["getwd()"],"metadata":{"id":"kdDTbnIqeLrc"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["list.files()"],"metadata":{"id":"IntIlf7ueWSl"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["subdir_preprocessed"],"metadata":{"id":"nw9oOt-heGdW"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["list.files(pattern=\"*.csv\")"],"metadata":{"id":"7EQlgf_jegUf"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# files <- list.files(path=subdir_preprocessed, pattern=\"*.csv\", full.names=TRUE, recursive=FALSE)\n","files <- list.files(pattern=\"*.csv\", full.names=TRUE, recursive=FALSE)\n","length(files)"],"metadata":{"id":"5eYXDCegc93b"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["files[1]"],"metadata":{"id":"7hJpMSWyfV98"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["(strsplit(files[1], '[/.]')[[1]])[3]"],"metadata":{"id":"CPIRcE1kt-0S"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["for (afile in files) {\n","  # afile = .\n","  file_root = (strsplit(afile, '[/.]')[[1]])[3]\n","  file_roots_v <- c(file_roots_v, file_root)\n","}"],"metadata":{"id":"lDqDn_4rvQw7"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["length(file_roots_v)"],"metadata":{"id":"FuBmxedywlwS"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["library(stringr)"],"metadata":{"id":"Yn2HI7fSs1Ju"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["tibble(files) %>%\n","  separate(files, into = c(\"lv1\", \"lv2\", \"lv3\"), sep = \"/\", fill = \"left\") %>%\n","  mutate(\"version\" = str_extract(lv3, regex(\"v\\\\d+\")))"],"metadata":{"id":"dAGazJF3s4Qh"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["files[0]"],"metadata":{"id":"xOWBlj54s4NZ"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["lapply(files, function(x) {\n","  print(paste0('\\nNovel: ', x))\n","  # anovel_df <- read.csv(file = x, header=FALSE)\n","  syuzhetr_df <- get_syuzhetr_sentiments(x)\n","  sentimentr_df <- get_sentimentr_sentiments(x)\n","\n","  anovel_sentiments_df <- merge(sentimentr_df, syuzhetr_df)\n","  # head(anovel_sentiments_df, 5)\n","\n","  file_root = (strsplit(x, '[/.]')[[1]])[3]\n","  outfile <- paste0('sentiments_', file_root, '.csv')\n","  print(paste0('  saving to: ', outfile))\n","  write.csv(x=anovel_sentiments_df, file=outfile, row.names=FALSE)\n","})"],"metadata":{"id":"SEeqmR41fLpO"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":[""],"metadata":{"id":"Qn9BQ9TR06YF"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":[""],"metadata":{"id":"K2SnWe2p032B"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["lapply(files, function(x) {\n","  carSpeeds <- read.csv(file = 'data/car-speeds.csv')\n","  head(carSpeeds)\n","\n","  \n","    t <- read.table(x, header=TRUE) # load file\n","    # apply function\n","    out <- function(t)\n","    # write to file\n","    write.table(out, \"path/to/output\", sep=\"\\t\", quote=FALSE, row.names=FALSE, col.names=TRUE)\n","})"],"metadata":{"id":"7HRFtm_Uc71B"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":[""],"metadata":{"id":"8kTi-nb5c7x-"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":[""],"metadata":{"id":"LDn9ddmlc7up"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["# **END OF NOTEBOOK**"],"metadata":{"id":"QuaYWn54M5hn"}},{"cell_type":"code","source":["sentiment_all <- left_just(data.frame(\n","    sentimentr_jockersrinker = round(sentiment(s_v, question.weight = 0)[[\"sentiment\"]], 2),\n","    sentimentr_jockers = round(sentiment(s_v, lexicon::hash_sentiment_jockers, question.weight = 0)[[\"sentiment\"]], 2),    \n","    sentimentr_huliu = round(sentiment(s_v, lexicon::hash_sentiment_huliu, question.weight = 0)[[\"sentiment\"]], 2),    \n","    sentimentr_sentiword = round(sentiment(s_v, lexicon::hash_sentiment_sentiword, question.weight = 0)[[\"sentiment\"]], 2),    \n","))"],"metadata":{"id":"A3p06CCYLKMg"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":[""],"metadata":{"id":"YS4PwAubLKJZ"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["left_just(data.frame(\n","    # stanford = sentiment_stanford(s_v)[[\"sentiment\"]],\n","    sentimentr_jockersrinker = round(sentiment(s_v, question.weight = 0)[[\"sentiment\"]], 2),\n","    sentimentr_jockers = round(sentiment(s_v, lexicon::hash_sentiment_jockers, question.weight = 0)[[\"sentiment\"]], 2),    \n","    sentimentr_huliu = round(sentiment(s_v, lexicon::hash_sentiment_huliu, question.weight = 0)[[\"sentiment\"]], 2),    \n","    sentimentr_sentiword = round(sentiment(s_v, lexicon::hash_sentiment_sentiword, question.weight = 0)[[\"sentiment\"]], 2),    \n","    RSentiment = calculate_score(s_v), \n","    SentimentAnalysis,\n","    meanr = score(s_v)[['score']],\n","    syuzhet,\n","    sentences = s_v,\n","    stringsAsFactors = FALSE\n","), \"sentences\")"],"metadata":{"id":"BO71cNOfFpo8"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":[""],"metadata":{"id":"ToN1OHF6FpmN"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":[""],"metadata":{"id":"DmDBCmX_Fpjt"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":[""],"metadata":{"id":"oxXQ1UHyFphR"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":[""],"metadata":{"id":"KM0gNueXFpdz"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":[""],"metadata":{"id":"0D1PJlzAFpa1"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["os <- import(\"os\")\n","os$listdir(\".\")"],"metadata":{"id":"z8SE9rA34UDH"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["typeof(novel_df['text_clean'])"],"metadata":{"id":"nnMXh3uW4UDJ"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["print(novel_df['text_clean'])"],"metadata":{"id":"rnhPMAWf4UDK"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["(novel_df['text_clean'])"],"metadata":{"id":"3d4QyWyF4_Nk"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["library(stringi)"],"metadata":{"id":"EZ71O5gG4UDL"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["novel_str = stri_join_list(novel_df['text_clean'], sep=' ', collapse=TRUE)\n","typeof(novel_str)"],"metadata":{"id":"xUrgE0I94UDM"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["substr(novel_str, 1, 100)"],"metadata":{"id":"EAzlclyf4UDN"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["bovary_s_v <- get_sentences(bovary_str)\n","bovary_s_v"],"metadata":{"id":"gaiYCX4U4UDO"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["typeof(bovary_s_v)"],"metadata":{"id":"NI6zal3Y424n"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["bovary_sentiment <- get_sentiment(bovary_s_v)"],"metadata":{"id":"hqjo7B0p6qph"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["typeof(bovary_sentiment)"],"metadata":{"id":"CJ1Mavq16s1d"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["\n","simple_plot(bovary_sentiment)"],"metadata":{"id":"PwQjpeC-6Y_B"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"1M8Wrd50Zyfr"},"source":["## Installing libraries"]},{"cell_type":"code","source":["install.packages('reticulate')"],"metadata":{"id":"zPMo4QJhljoo"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# which version of python are we using, where is it?\n","\n","cli_msg <- system('which python', intern=TRUE)\n","cli_msg"],"metadata":{"id":"TM3nDIq2l0bg"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# in RStudio, type 'usethis::edit_r_profile()' add this line\n","\n","Sys.setenv(RETICULATE_PYTHON = \"/usr/local/bin/python\")\n","\n","library(reticulate)"],"metadata":{"id":"IX5nGIZFl0YN"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["print(\"hello\")"],"metadata":{"id":"ySQK7sx1ljxx"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["repl_python(input='print(\"hello\")')"],"metadata":{"id":"syC685WMljux"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["system('wget https://raw.githubusercontent.com/mwaskom/seaborn-data/master/flights.csv', intern=TRUE)\n"],"metadata":{"id":"9lmg1x9no2ZY"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["cli_msg <- system('ls -altr', intern=TRUE)\n","cli_msg"],"metadata":{"id":"FOPuF_pepCWy"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["os <- import(\"os\")\n","os$listdir(\".\")"],"metadata":{"id":"P5lzzlBjng26"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["#importing required Python libraries/modules\n","sns <- import('seaborn')\n","plt <- import('matplotlib.pyplot')\n","pd <- import('pandas')"],"metadata":{"id":"rwa7a0I0s1HF"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["# Syuzhet"],"metadata":{"id":"vT5-64th0vSC"}},{"cell_type":"code","source":["install.packages('syuzhet')"],"metadata":{"id":"chGGhsTXuO1_"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["library(syuzhet)"],"metadata":{"id":"cpCMCCgZuY25"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["install.packages('gutenbergr')"],"metadata":{"id":"u_H1E9zKuYzi"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["library(gutenbergr)"],"metadata":{"id":"0psVPK6tuYwi"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["library(dplyr)"],"metadata":{"id":"RBGscwIguYmj"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["gutenberg_metadata %>%\n","  filter(title == \"Wuthering Heights\")"],"metadata":{"id":"_Nfj2DlvuxiR"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["gutenberg_works(author == \"Austen, Jane\")"],"metadata":{"id":"XgCbLI_huxe8"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["library(stringr)\n","gutenberg_works(str_detect(author, \"Austen\"))"],"metadata":{"id":"nwkIUenbuxcT"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["library(stringr)\n","gutenberg_works(str_detect(title, \"Bovary\"))"],"metadata":{"id":"iVU1YUpuuxZB"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["bovary <- gutenberg_download(2413)\n","bovary"],"metadata":{"id":"v-kfZSGNuxWB"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["os <- import(\"os\")\n","os$listdir(\".\")"],"metadata":{"id":"fbB6c_c2wOyV"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["typeof(bovary[1])"],"metadata":{"id":"qp3Cwy2RwgEl"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["typeof(bovary[2][0])"],"metadata":{"id":"7aoq9RdXxED_"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["library(stringi)"],"metadata":{"id":"32ZpehAVzhHm"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["bovary_str = stri_join_list(bovary[2], sep=' ', collapse=TRUE)\n","typeof(bovary_str)"],"metadata":{"id":"TCCcqXYVzVcV"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["substr(bovary_str, 1, 100)"],"metadata":{"id":"Dt4Wh6-FzvFt"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["s_v <- get_sentences(bovary_str)\n","s_v"],"metadata":{"id":"Nes-i4u0zvCh"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["s_v_sentiment <- get_sentiment(s_v)\n","s_v_sentiment"],"metadata":{"id":"uY9Uv3wYzu_s"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["simple_plot(s_v_sentiment)"],"metadata":{"id":"pN1Y6ebmzu8i"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":[""],"metadata":{"id":"3H87wy_czu52"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":[""],"metadata":{"id":"nODIGvlNzu21"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["bovary_str = str_flatten(bovary[2], \" \")"],"metadata":{"id":"Z4G0SOf_xfw4"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["bovary_str2 = str_flatten(noquote(bovary[2]), \" \")"],"metadata":{"id":"yMW9E7j8ypnf"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["bovary_str2"],"metadata":{"id":"mEt6llpZy0AU"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["typeof(bovary_str)"],"metadata":{"id":"hANubX9Ixpq7"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["bovary_str"],"metadata":{"id":"VUQVH9CRyGmo"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["bovary_v <- get_sentences(bovary_str)"],"metadata":{"id":"LjM4Kjz0xso9"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["typeof(bovary_v)"],"metadata":{"id":"HSDd-bjgx7tE"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":[""],"metadata":{"id":"J7_Dd-Rxx9NV"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":[""],"metadata":{"id":"ZqyZ9U5Vx9Jk"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["sent_v <- get_sentences(bovary)"],"metadata":{"id":"L5ZIsnEyv6D8"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":[""],"metadata":{"id":"pkXv69JSv6Al"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":[""],"metadata":{"id":"aR-1ghUqv59i"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":[""],"metadata":{"id":"huvchoilv57Z"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":[""],"metadata":{"id":"M_DTXPSNv51c"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["```{python}\n","import os\n","```"],"metadata":{"id":"SgPkjFfYtmsD"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["#using R's inbuilt AirPassengers dataset\n","df <- datasets::AirPassengers\n","\n","#converting Time-Series object into an R Dataframe \n","#Thx: https://stackoverflow.com/questions/5331901/transforming-a-time-series-into-a-data-frame-and-back\n","df1 <- data.frame(tapply(df, list(year = floor(time(df)), month = month.abb[cycle(df)]), c))\n","df1 <- df1[month.abb]\n","\n","#building a heatmap using seaborn \n","#please note the function r_to_py() that converts R object into a python \n","sns$heatmap(r_to_py(df1), fmt=\"g\", cmap ='viridis')\n","\n","#display the plot\n","plt$show()"],"metadata":{"id":"lJAYm4TNs8tf"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["```{python}\n","\n","name = 'Bill'\n","\n","print(f'Hello {name}!')\n","```"],"metadata":{"id":"eF1hBKyIo18X"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["```{python}\n","import pandas as pd\n","\n","flights = pd.read_csv('flights.csv')\n","flights = flights[flights['dest'] == \"ORD\"]\n","flights = flights[['carrier', 'dep_delay', 'arr_delay']]\n","flights = flights.dropna()\n","```"],"metadata":{"id":"8QEZ9WDzngz3"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# using R's inbuilt AirPassengers dataset\n","df <- datasets::AirPassengers"],"metadata":{"id":"9ZkEIPMIngw-"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["df"],"metadata":{"id":"GH0gQa7UnguH"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":[""],"metadata":{"id":"xxx5rfDfljrk"},"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"tg4XUaNygDBp"},"source":["install.packages('caret')"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"g_5maO-eZt_n"},"source":["install.packages('mlbench')"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"RZ1-XnpzZ1uA"},"source":["## Importing libraries"]},{"cell_type":"code","metadata":{"id":"H6opECZygIYB"},"source":["library(caret)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"0FThma96hDGu"},"source":["library(ggplot2)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"2xwKBBtBZq0i"},"source":["library(mlbench)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"75lo2yDzbHJI"},"source":["## How many CPU cores are there?"]},{"cell_type":"code","metadata":{"id":"6mQwtgVtYfDp"},"source":["library(parallel)\n","detectCores(all.tests = FALSE, logical = TRUE)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"wC5G278gYgnh"},"source":[""],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"sb3ldtjKZLEO"},"source":["---"]},{"cell_type":"markdown","metadata":{"id":"pHEG_t5TZPHp"},"source":["# Machine Learning in R: Building a Linear Regression Model\n","\n","YouTube:\n","https://www.youtube.com/watch?v=el8xP38SWdk\n","\n","GitHub:\n","https://github.com/dataprofessor/code/blob/master/linear-regression/boston-housing-linear-regression.R"]},{"cell_type":"code","metadata":{"id":"3fiO8MnhZLpR"},"source":["############################################\n","# Data Professor                           #\n","# http://youtube.com/dataprofessor         #\n","# http://github.com/dataprofessor          #\n","# http://facebook.com/dataprofessor        #\n","# https://www.instagram.com/data.professor #\n","############################################\n","\n","# Importing libraries\n","library(mlbench) # Contains several benchmark data sets (especially the Boston Housing dataset)\n","library(caret) # Package for machine learning algorithms / CARET stands for Classification And REgression Training\n","\n","# Importing the Boston Housing data set\n","data(BostonHousing)\n","\n","head(BostonHousing)\n","\n","# Check to see if there are missing data?\n","sum(is.na(BostonHousing))\n","\n","# To achieve reproducible model; set the random seed number\n","set.seed(100)\n","\n","# Performs stratified random split of the data set\n","TrainingIndex <- createDataPartition(BostonHousing$medv, p=0.8, list = FALSE)\n","TrainingSet <- BostonHousing[TrainingIndex,] # Training Set\n","TestingSet <- BostonHousing[-TrainingIndex,] # Test Set\n","\n","\n","###############################\n","\n","# Build Training model\n","Model <- train(medv ~ ., data = TrainingSet,\n","               method = \"lm\",\n","               na.action = na.omit,\n","               preProcess=c(\"scale\",\"center\"),\n","               trControl= trainControl(method=\"none\")\n",")\n","\n","# Apply model for prediction\n","Model.training <-predict(Model, TrainingSet) # Apply model to make prediction on Training set\n","Model.testing <-predict(Model, TestingSet) # Apply model to make prediction on Testing set\n","\n","# Model performance (Displays scatter plot and performance metrics)\n","  # Scatter plot of Training set\n","plot(TrainingSet$medv,Model.training, col = \"blue\" )\n","plot(TestingSet$medv,Model.testing, col = \"blue\" )"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"Z2ADWh-aaImU"},"source":["---"]},{"cell_type":"markdown","metadata":{"id":"NZEyHueIaO-3"},"source":["# Machine Learning in R: Building a Linear Regression Model\n","\n","YouTube:\n","https://www.youtube.com/watch?v=el8xP38SWdk\n","\n","GitHub:\n","https://github.com/dataprofessor/code/blob/master/linear-regression/boston-housing-linear-regression.R"]},{"cell_type":"markdown","metadata":{"id":"RPA-GswKaiWB"},"source":["### Importing libraries"]},{"cell_type":"code","metadata":{"id":"ckxyvMW0aJcj"},"source":["library(mlbench) # Contains several benchmark data sets (especially the Boston Housing dataset)\n","library(caret) # Package for machine learning algorithms / CARET stands for Classification And REgression Training"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"-F0DOdsWapUw"},"source":["### Importing the Boston Housing data set"]},{"cell_type":"code","metadata":{"id":"swSz9CEiadFg"},"source":["data(BostonHousing)\n","\n","head(BostonHousing)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"3Xs-F6p9at-y"},"source":["### Check to see if there are missing data?"]},{"cell_type":"code","metadata":{"id":"OHCPeCGPafgt"},"source":["sum(is.na(BostonHousing))"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"HkUTKmyHa077"},"source":["### To achieve reproducible model; set the random seed number"]},{"cell_type":"code","metadata":{"id":"t5kGo_gWaxNX"},"source":["set.seed(100)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"wRgqjdaua78K"},"source":["### Performs stratified random split of the data set"]},{"cell_type":"code","metadata":{"id":"wgO_WlOma3fp"},"source":["TrainingIndex <- createDataPartition(BostonHousing$medv, p=0.8, list = FALSE)\n","TrainingSet <- BostonHousing[TrainingIndex,] # Training Set\n","TestingSet <- BostonHousing[-TrainingIndex,] # Test Set"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"maKWTngSbM3w"},"source":["### Build Training model"]},{"cell_type":"code","metadata":{"id":"TIJNfeiDa9iN"},"source":["Model <- train(medv ~ ., data = TrainingSet,\n","               method = \"lm\",\n","               na.action = na.omit,\n","               preProcess=c(\"scale\",\"center\"),\n","               trControl= trainControl(method=\"none\")\n",")"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"R2sr002FbRkV"},"source":["### Apply model for prediction"]},{"cell_type":"code","metadata":{"id":"9Cccu6lxbXGY"},"source":["Model.training <-predict(Model, TrainingSet) # Apply model to make prediction on Training set\n","Model.testing <-predict(Model, TestingSet) # Apply model to make prediction on Testing set\n"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"mIklYas6bUxd"},"source":["### Model performance (Displays scatter plot and performance metrics)\n","Scatter plot of Training set"]},{"cell_type":"code","metadata":{"id":"dRHLuD2IbPcA"},"source":["plot(TrainingSet$medv,Model.training, col = \"blue\" )"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"xc39erd3bnKH"},"source":["Scatter plot of Testing set"]},{"cell_type":"code","metadata":{"id":"TxERQOCnbbOW"},"source":["plot(TestingSet$medv,Model.testing, col = \"blue\" )"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"RiYqSKT3bpCg"},"source":[""],"execution_count":null,"outputs":[]}]}